#!/usr/bin/env python3
"""
ì„œë²„ DB ë°ì´í„°ë¥¼ ë¡œì»¬ DBë¡œ ë™ê¸°í™”í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python3 sync_server_data.py

í™˜ê²½ ë³€ìˆ˜:
    SERVER_DATABASE_URL: ì„œë²„ DB ì—°ê²° ë¬¸ìì—´ (ì˜ˆ: postgresql://user:pass@server:5432/dbname)
    DATABASE_URL: ë¡œì»¬ DB ì—°ê²° ë¬¸ìì—´ (ê¸°ë³¸ê°’: .env íŒŒì¼ì—ì„œ ì½ìŒ)
"""

import os
import sys
from datetime import datetime
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()
backend_env_path = os.path.join(os.path.dirname(__file__), ".env")
if os.path.exists(backend_env_path):
    load_dotenv(dotenv_path=backend_env_path, override=True)

from db_manager import db_manager
from psycopg_pool import ConnectionPool
from psycopg import sql
from psycopg.types.json import Json
import psycopg


def get_server_db_url():
    """ì„œë²„ DB ì—°ê²° URL ë°˜í™˜"""
    server_db_url = os.getenv("SERVER_DATABASE_URL")
    if not server_db_url:
        raise ValueError(
            "SERVER_DATABASE_URL í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
            "ì˜ˆ: export SERVER_DATABASE_URL=postgresql://user:pass@server:5432/dbname\n"
            "ë˜ëŠ” SSH í„°ë„ë§ ì‚¬ìš©: export SERVER_DATABASE_URL=postgresql://user:pass@localhost:5433/dbname"
        )
    
    print(f"ğŸ”— ì„œë²„ DB ì—°ê²° ì •ë³´ í™•ì¸...")
    print(f"   ì—°ê²° ì •ë³´: {server_db_url.split('@')[0]}@***")
    return server_db_url


def sync_table(server_db_url, target_pool, table_name, batch_size=1000):
    """í…Œì´ë¸” ë™ê¸°í™”"""
    print(f"\nğŸ“Š {table_name} í…Œì´ë¸” ë™ê¸°í™” ì‹œì‘...")
    
    # ì§ì ‘ ì—°ê²° ì‚¬ìš© (ConnectionPool ëŒ€ì‹ )
    with psycopg.connect(server_db_url) as source_conn:
        with source_conn.cursor() as source_cur:
            # ì†ŒìŠ¤ í…Œì´ë¸” ë°ì´í„° ê°œìˆ˜ í™•ì¸
            source_cur.execute(f"SELECT COUNT(*) FROM {table_name}")
            source_count = source_cur.fetchone()[0]
            print(f"  - ì„œë²„ ë°ì´í„°: {source_count}ê°œ")
            
            if source_count == 0:
                print(f"  âš ï¸ ì„œë²„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                return 0
            
            # íƒ€ê²Ÿ í…Œì´ë¸” ì¡´ì¬ í™•ì¸ ë° ì»¬ëŸ¼ í™•ì¸
            from db_manager import db_manager
            with db_manager.get_cursor(commit=False) as check_cur:
                # í…Œì´ë¸” ì¡´ì¬ í™•ì¸
                check_cur.execute("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_schema = 'public' 
                        AND table_name = %s
                    )
                """, (table_name,))
                table_exists = check_cur.fetchone()[0]
                
                if not table_exists:
                    print(f"  âš ï¸ ë¡œì»¬ DBì— {table_name} í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                    return 0
                
                check_cur.execute(f"""
                    SELECT column_name 
                    FROM information_schema.columns 
                    WHERE table_name = %s 
                    ORDER BY ordinal_position
                """, (table_name,))
                target_columns = [row[0] for row in check_cur.fetchall()]
            
            if not target_columns:
                print(f"  âš ï¸ ë¡œì»¬ DBì— {table_name} í…Œì´ë¸”ì˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                return 0
            
            # ì†ŒìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (íƒ€ê²Ÿì— ìˆëŠ” ì»¬ëŸ¼ë§Œ)
            columns_str = ', '.join(target_columns)
            source_cur.execute(f"SELECT {columns_str} FROM {table_name}")
            columns = [desc[0] for desc in source_cur.description]
            print(f"  - ì»¬ëŸ¼: {len(columns)}ê°œ (íƒ€ê²Ÿê³¼ ì¼ì¹˜í•˜ëŠ” ì»¬ëŸ¼ë§Œ)")
            
            # JSONB ì»¬ëŸ¼ í™•ì¸ (dict íƒ€ì… ì²˜ë¦¬ í•„ìš”)
            jsonb_columns = set()
            for i, col in enumerate(columns):
                col_type = source_cur.description[i].type_code
                if col_type and 'json' in str(col_type).lower():
                    jsonb_columns.add(col)
            
            # íƒ€ê²Ÿ í…Œì´ë¸”ì— ë°ì´í„° ì‚½ì…
            from db_manager import db_manager
            import json
            with db_manager.get_cursor(commit=True) as target_cur:
                # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì„ íƒì‚¬í•­ - ì£¼ì„ í•´ì œí•˜ë©´ ì „ì²´ êµì²´)
                # target_cur.execute(f"TRUNCATE TABLE {table_name} CASCADE")
                
                inserted = 0
                batch = []
                
                for row in source_cur:
                    # ëª¨ë“  dict/list íƒ€ì…ì„ Jsonìœ¼ë¡œ ë³€í™˜
                    processed_row = list(row)
                    for i, (val, col) in enumerate(zip(processed_row, columns)):
                        if val is not None and isinstance(val, (dict, list)):
                            # psycopgì˜ Json ì–´ëŒ‘í„° ì‚¬ìš©
                            processed_row[i] = Json(val)
                        # users í…Œì´ë¸”ì˜ provider_idê°€ nullì´ë©´ email ì‚¬ìš©
                        elif table_name == 'users' and col == 'provider_id' and val is None:
                            # email ì»¬ëŸ¼ ì°¾ê¸°
                            email_idx = columns.index('email') if 'email' in columns else None
                            if email_idx is not None and processed_row[email_idx]:
                                processed_row[i] = processed_row[email_idx]
                            else:
                                processed_row[i] = 'local'
                    batch.append(tuple(processed_row))
                    
                    if len(batch) >= batch_size:
                        # ë°°ì¹˜ ì‚½ì…
                        placeholders = ', '.join(['%s'] * len(columns))
                        columns_str = ', '.join(columns)
                        
                        # Primary Key ë™ì  í™•ì¸
                        from db_manager import db_manager
                        with db_manager.get_cursor(commit=False) as pk_cur:
                            pk_cur.execute("""
                                SELECT constraint_name, constraint_type
                                FROM information_schema.table_constraints
                                WHERE table_name = %s AND constraint_type = 'PRIMARY KEY'
                            """, (table_name,))
                            pk_info = pk_cur.fetchone()
                            
                            if pk_info:
                                pk_cur.execute("""
                                    SELECT column_name
                                    FROM information_schema.key_column_usage
                                    WHERE constraint_name = %s
                                    ORDER BY ordinal_position
                                """, (pk_info[0],))
                                pk_cols = [row[0] for row in pk_cur.fetchall()]
                                conflict_cols = ', '.join(pk_cols)
                                
                                # UPSERT (ON CONFLICT DO UPDATE)
                                update_set = ', '.join([f"{col} = EXCLUDED.{col}" for col in columns if col not in pk_cols])
                                query = f"""
                                    INSERT INTO {table_name} ({columns_str})
                                    VALUES ({placeholders})
                                    ON CONFLICT ({conflict_cols}) DO UPDATE SET {update_set}
                                """
                            else:
                                # Primary Keyê°€ ì—†ìœ¼ë©´ ì¼ë°˜ INSERT
                                query = f"""
                                    INSERT INTO {table_name} ({columns_str})
                                    VALUES ({placeholders})
                                    ON CONFLICT DO NOTHING
                                """
                        
                        target_cur.executemany(query, batch)
                        inserted += len(batch)
                        batch = []
                        
                        if inserted % (batch_size * 10) == 0:
                            print(f"  - ì§„í–‰: {inserted}/{source_count} ({inserted*100//source_count}%)")
                
                # ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬
                if batch:
                    placeholders = ', '.join(['%s'] * len(columns))
                    columns_str = ', '.join(columns)
                    
                    # Primary Key ë™ì  í™•ì¸ (ë°°ì¹˜ ì²˜ë¦¬ìš©)
                    from db_manager import db_manager
                    with db_manager.get_cursor(commit=False) as pk_cur:
                        pk_cur.execute("""
                            SELECT constraint_name, constraint_type
                            FROM information_schema.table_constraints
                            WHERE table_name = %s AND constraint_type = 'PRIMARY KEY'
                        """, (table_name,))
                        pk_info = pk_cur.fetchone()
                        
                        if pk_info:
                            pk_cur.execute("""
                                SELECT column_name
                                FROM information_schema.key_column_usage
                                WHERE constraint_name = %s
                                ORDER BY ordinal_position
                            """, (pk_info[0],))
                            pk_cols = [row[0] for row in pk_cur.fetchall()]
                            conflict_cols = ', '.join(pk_cols)
                            
                            # UPSERT (ON CONFLICT DO UPDATE)
                            update_set = ', '.join([f"{col} = EXCLUDED.{col}" for col in columns if col not in pk_cols])
                            query = f"""
                                INSERT INTO {table_name} ({columns_str})
                                VALUES ({placeholders})
                                ON CONFLICT ({conflict_cols}) DO UPDATE SET {update_set}
                            """
                        else:
                            # Primary Keyê°€ ì—†ìœ¼ë©´ ì¼ë°˜ INSERT
                            query = f"""
                                INSERT INTO {table_name} ({columns_str})
                                VALUES ({placeholders})
                                ON CONFLICT DO NOTHING
                            """
                    
                    target_cur.executemany(query, batch)
                    inserted += len(batch)
                
                # íƒ€ê²Ÿ í…Œì´ë¸” ë°ì´í„° ê°œìˆ˜ í™•ì¸
                target_cur.execute(f"SELECT COUNT(*) FROM {table_name}")
                target_count = target_cur.fetchone()[0]
                
                print(f"  âœ… ë™ê¸°í™” ì™„ë£Œ: {inserted}ê°œ ì‚½ì…, ì´ {target_count}ê°œ")
                return inserted


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸš€ ì„œë²„ DB â†’ ë¡œì»¬ DB ë™ê¸°í™” ì‹œì‘")
    print("=" * 60)
    
    try:
        # ì„œë²„ DB ì—°ê²° ì •ë³´ í™•ì¸
        server_db_url = get_server_db_url()
        
        # ë¡œì»¬ DB ì—°ê²° í™•ì¸
        print(f"\nğŸ”— ë¡œì»¬ DB ì—°ê²° í™•ì¸...")
        with db_manager.get_cursor(commit=False) as cur:
            cur.execute("SELECT version()")
            version = cur.fetchone()[0]
            print(f"  âœ… ë¡œì»¬ DB ì—°ê²° ì„±ê³µ: {version[:50]}...")
        
        # ë™ê¸°í™”í•  í…Œì´ë¸” ëª©ë¡ (ì „ì²´ í…Œì´ë¸”)
        # ì„œë²„ DBì—ì„œ í…Œì´ë¸” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        with psycopg.connect(server_db_url) as conn:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT table_name 
                    FROM information_schema.tables 
                    WHERE table_schema = 'public' 
                    AND table_type = 'BASE TABLE'
                    AND table_name NOT IN ('pg_stat_statements', 'pg_stat_statements_info')
                    ORDER BY table_name
                """)
                tables_to_sync = [row[0] for row in cur.fetchall()]
        
        print(f"\nğŸ“‹ ë™ê¸°í™”í•  í…Œì´ë¸”: {len(tables_to_sync)}ê°œ")
        for table in tables_to_sync:
            print(f"   - {table}")
        
        total_synced = 0
        start_time = datetime.now()
        
        # ì„œë²„ DB URL ê°€ì ¸ì˜¤ê¸°
        server_db_url = get_server_db_url()
        
        for table_name in tables_to_sync:
            try:
                synced = sync_table(server_db_url, None, table_name)
                total_synced += synced
            except Exception as e:
                print(f"  âŒ {table_name} ë™ê¸°í™” ì‹¤íŒ¨: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        elapsed = (datetime.now() - start_time).total_seconds()
        
        print("\n" + "=" * 60)
        print(f"âœ… ë™ê¸°í™” ì™„ë£Œ!")
        print(f"  - ì´ {total_synced}ê°œ ë ˆì½”ë“œ ë™ê¸°í™”")
        print(f"  - ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

