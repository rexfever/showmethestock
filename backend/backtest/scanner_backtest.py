#!/usr/bin/env python3
"""
ìŠ¤ìºë„ˆ ë°±í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ë‚ ì§œ ë²”ìœ„ë¥¼ ì§€ì •í•˜ì—¬ ìŠ¤ìº”ì„ ì‹¤í–‰í•˜ê³  ì„±ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
ìºì‹œ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ë¹ ë¥´ê²Œ ì‹¤í–‰í•©ë‹ˆë‹¤.
"""
import sys
import os
import argparse
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
from pathlib import Path
import json
import pandas as pd

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from date_helper import normalize_date, yyyymmdd_to_date
from main import is_trading_day
from config import config
from kiwoom_api import api
from market_analyzer import market_analyzer
from services.scan_service import execute_scan_with_fallback
from scanner_factory import get_scanner
from scanner_settings_manager import get_scanner_version, get_regime_version
import holidays


def get_trading_days(start_date: str, end_date: str) -> List[str]:
    """ì‹œì‘ì¼ë¶€í„° ì¢…ë£Œì¼ê¹Œì§€ì˜ ê±°ë˜ì¼ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    start_dt = datetime.strptime(start_date, "%Y%m%d")
    end_dt = datetime.strptime(end_date, "%Y%m%d")
    
    # í•œêµ­ ê³µíœ´ì¼
    kr_holidays = holidays.SouthKorea(years=range(start_dt.year, end_dt.year + 2))
    
    trading_days = []
    current = start_dt
    while current <= end_dt:
        date_str = current.strftime("%Y%m%d")
        # ì£¼ë§ ì²´í¬
        if current.weekday() < 5:  # ì›”~ê¸ˆ
            # ê³µíœ´ì¼ ì²´í¬
            if current.date() not in kr_holidays:
                trading_days.append(date_str)
        current += timedelta(days=1)
    
    return trading_days


def get_nth_trading_day(start_date: str, n: int) -> Optional[str]:
    """
    ì‹œì‘ì¼ë¶€í„° Në²ˆì§¸ ê±°ë˜ì¼ ë°˜í™˜
    
    Args:
        start_date: ì‹œì‘ ë‚ ì§œ (YYYYMMDD)
        n: Në²ˆì§¸ ê±°ë˜ì¼ (1 = ë‹¤ìŒ ê±°ë˜ì¼, 2 = ë‹¤ë‹¤ìŒ ê±°ë˜ì¼, ...)
    
    Returns:
        Në²ˆì§¸ ê±°ë˜ì¼ (YYYYMMDD), ì°¾ì§€ ëª»í•˜ë©´ None
    """
    if n <= 0:
        return start_date
    
    start_dt = datetime.strptime(start_date, "%Y%m%d")
    kr_holidays = holidays.SouthKorea(years=range(start_dt.year, start_dt.year + 2))
    
    # ì¶©ë¶„í•œ ë²”ìœ„ê¹Œì§€ ê±°ë˜ì¼ ì°¾ê¸° (ìµœëŒ€ 30ì¼ í›„ê¹Œì§€)
    end_dt = start_dt + timedelta(days=max(n * 2 + 10, 30))
    
    trading_days = []
    current = start_dt
    while current <= end_dt and len(trading_days) < n:
        # ì£¼ë§ ì²´í¬
        if current.weekday() < 5:  # ì›”~ê¸ˆ
            # ê³µíœ´ì¼ ì²´í¬
            if current.date() not in kr_holidays:
                trading_days.append(current.strftime("%Y%m%d"))
        current += timedelta(days=1)
    
    # Në²ˆì§¸ ê±°ë˜ì¼ ë°˜í™˜ (ì¸ë±ìŠ¤ëŠ” 0ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ n-1)
    if len(trading_days) >= n:
        return trading_days[n - 1]
    elif trading_days:
        # Në²ˆì§¸ë¥¼ ì°¾ì§€ ëª»í–ˆì§€ë§Œ ë§ˆì§€ë§‰ ê±°ë˜ì¼ ë°˜í™˜
        return trading_days[-1]
    else:
        return None


def get_universe(kospi_limit: int = None, kosdaq_limit: int = None, date: str = None) -> List[str]:
    """ìœ ë‹ˆë²„ìŠ¤ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
    kp = kospi_limit or config.universe_kospi
    kd = kosdaq_limit or config.universe_kosdaq
    
    try:
        kospi = api.get_top_codes('KOSPI', kp)
        kosdaq = api.get_top_codes('KOSDAQ', kd)
        universe = [*kospi, *kosdaq]
        return universe
    except Exception as e:
        print(f"âš ï¸ ìœ ë‹ˆë²„ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []


def run_scan_for_date(
    date: str,
    kospi_limit: int = None,
    kosdaq_limit: int = None,
    scanner_version: str = None,
    regime_version: str = None,
    use_cache: bool = True
) -> Dict:
    """
    íŠ¹ì • ë‚ ì§œì— ëŒ€í•œ ìŠ¤ìº” ì‹¤í–‰
    
    Args:
        date: ìŠ¤ìº” ë‚ ì§œ (YYYYMMDD)
        kospi_limit: KOSPI ì¢…ëª© ìˆ˜ ì œí•œ
        kosdaq_limit: KOSDAQ ì¢…ëª© ìˆ˜ ì œí•œ
        scanner_version: ìŠ¤ìºë„ˆ ë²„ì „ (v1/v2), Noneì´ë©´ DBì—ì„œ ì½ìŒ
        regime_version: ë ˆì§ ë¶„ì„ ë²„ì „ (v1/v3/v4), Noneì´ë©´ DBì—ì„œ ì½ìŒ
        use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€
    
    Returns:
        ìŠ¤ìº” ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    try:
        # ë‚ ì§œ ì •ê·œí™”
        normalized_date = normalize_date(date)
        
        # ê±°ë˜ì¼ ì²´í¬
        if not is_trading_day(normalized_date):
            return {
                "date": normalized_date,
                "success": False,
                "error": "ê±°ë˜ì¼ì´ ì•„ë‹™ë‹ˆë‹¤",
                "items": [],
                "market_condition": None
            }
        
        # ìœ ë‹ˆë²„ìŠ¤ ì¡°íšŒ
        universe = get_universe(kospi_limit, kosdaq_limit, normalized_date)
        if not universe:
            return {
                "date": normalized_date,
                "success": False,
                "error": "ìœ ë‹ˆë²„ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨",
                "items": [],
                "market_condition": None
            }
        
        # ì‹œì¥ ìƒí™© ë¶„ì„
        market_condition = None
        if config.market_analysis_enable:
            try:
                if not use_cache:
                    market_analyzer.clear_cache()
                
                # ë ˆì§ ë²„ì „ ê²°ì •
                if regime_version is None:
                    try:
                        regime_version = get_regime_version()
                    except Exception:
                        regime_version = getattr(config, 'regime_version', 'v1')
                
                market_condition = market_analyzer.analyze_market_condition(
                    normalized_date,
                    regime_version=regime_version
                )
                
                # ë ˆì§ ë²„ì „ ë¡œê·¸
                if hasattr(market_condition, 'version'):
                    if market_condition.version == 'regime_v4':
                        print(f"  ğŸ“Š Regime v4: {market_condition.final_regime} "
                              f"(trend: {market_condition.global_trend_score:.2f}, "
                              f"risk: {market_condition.global_risk_score:.2f})")
                    elif market_condition.version == 'regime_v3':
                        print(f"  ğŸ“Š Regime v3: {market_condition.final_regime} "
                              f"(ì ìˆ˜: {market_condition.final_score:.2f})")
                    else:
                        print(f"  ğŸ“Š Regime v1: {market_condition.market_sentiment} "
                              f"(ìˆ˜ìµë¥ : {market_condition.kospi_return*100:.2f}%)")
            except Exception as e:
                print(f"  âš ï¸ ì‹œì¥ ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        # ìŠ¤ìºë„ˆ ë²„ì „ ê²°ì •
        if scanner_version is None:
            try:
                scanner_version = get_scanner_version()
            except Exception:
                scanner_version = getattr(config, 'scanner_version', 'v1')
        
        # ìŠ¤ìº” ì‹¤í–‰
        result = execute_scan_with_fallback(universe, normalized_date, market_condition)
        
        if len(result) == 3:
            items, chosen_step, actual_scanner_version = result
        else:
            items, chosen_step = result
            actual_scanner_version = scanner_version
        
        return {
            "date": normalized_date,
            "success": True,
            "items": items,
            "matched_count": len(items),
            "chosen_step": chosen_step,
            "scanner_version": actual_scanner_version,
            "regime_version": regime_version or getattr(config, 'regime_version', 'v1'),
            "market_condition": {
                "version": getattr(market_condition, 'version', 'regime_v1') if market_condition else None,
                "sentiment": getattr(market_condition, 'market_sentiment', None) if market_condition else None,
                "final_regime": getattr(market_condition, 'final_regime', None) if market_condition else None,
                "kospi_return": getattr(market_condition, 'kospi_return', None) if market_condition else None,
            } if market_condition else None,
            "universe_size": len(universe)
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {
            "date": date,
            "success": False,
            "error": str(e),
            "items": [],
            "market_condition": None
        }


def analyze_performance(scan_results: List[Dict], days_after: int = 5) -> Dict:
    """
    ìŠ¤ìº” ê²°ê³¼ì˜ ì„±ê³¼ ë¶„ì„
    
    Args:
        scan_results: ìŠ¤ìº” ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        days_after: ëª‡ ì¼ í›„ ê°€ê²©ìœ¼ë¡œ ì„±ê³¼ ì¸¡ì •í• ì§€
    
    Returns:
        ì„±ê³¼ ë¶„ì„ ê²°ê³¼ (ì—ëŸ¬ í†µê³„ í¬í•¨)
    """
    if not scan_results:
        return {
            "total_scans": 0,
            "total_items": 0,
            "analyzed_dates": 0,
            "overall_avg_return": 0,
            "overall_win_rate": 0,
            "performance_by_date": {},
            "errors": {
                "date_errors": [],
                "item_errors": [],
                "total_item_errors": 0
            }
        }
    
    total_scans = len([r for r in scan_results if r.get("success")])
    total_items = sum(len(r.get("items", [])) for r in scan_results if r.get("success"))
    
    # ë‚ ì§œë³„ ì„±ê³¼ ë¶„ì„
    performance_by_date = {}
    error_stats = {
        "date_errors": [],  # ë‚ ì§œë³„ ì—ëŸ¬
        "item_errors": [],  # ì¢…ëª©ë³„ ì—ëŸ¬ (ìµœëŒ€ 100ê°œ)
        "total_item_errors": 0  # ì „ì²´ ì¢…ëª© ì—ëŸ¬ ìˆ˜
    }
    
    for result in scan_results:
        if not result.get("success") or not result.get("items"):
            continue
        
        date = result["date"]
        items = result["items"]
        
        # Nì¼ í›„ ê°€ê²© ì¡°íšŒ (ì •í™•í•œ ê±°ë˜ì¼ ì°¾ê¸°)
        try:
            # Në²ˆì§¸ ê±°ë˜ì¼ ì°¾ê¸° (days_afterì¼ í›„ì˜ ê±°ë˜ì¼)
            target_date_str = get_nth_trading_day(date, days_after)
            if not target_date_str:
                # ê±°ë˜ì¼ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ì›ë˜ ë‚ ì§œ ì‚¬ìš©
                target_date_str = date
                error_stats["date_errors"].append({
                    "date": date,
                    "error": f"{days_after}ì¼ í›„ ê±°ë˜ì¼ì„ ì°¾ì§€ ëª»í•¨"
                })
            
            performance_data = []
            item_errors_for_date = []
            
            for item in items:
                code = item.get("ticker") or item.get("code")
                if not code:
                    item_errors_for_date.append({
                        "code": "UNKNOWN",
                        "error": "ì¢…ëª© ì½”ë“œ ì—†ìŒ"
                    })
                    error_stats["total_item_errors"] += 1
                    continue
                
                try:
                    # ìŠ¤ìº” ë‹¹ì¼ ê°€ê²©
                    scan_price = item.get("current_price") or item.get("close_price")
                    if not scan_price:
                        item_errors_for_date.append({
                            "code": code,
                            "error": "ê°€ê²© ì •ë³´ ì—†ìŒ"
                        })
                        error_stats["total_item_errors"] += 1
                        continue
                    
                    # Nì¼ í›„ ê°€ê²© ì¡°íšŒ (base_dt ëª…ì‹œì  ì‚¬ìš©, ìºì‹œ í™œìš©)
                    # base_dtë¥¼ ì§€ì •í•˜ì—¬ í•´ë‹¹ ë‚ ì§œ ê¸°ì¤€ ë°ì´í„° ì¡°íšŒ
                    df = api.get_ohlcv(code, count=1, base_dt=target_date_str)
                    if df.empty:
                        # ìºì‹œì—ì„œ ì°¾ì§€ ëª»í•œ ê²½ìš°, ë” ë§ì€ ë°ì´í„° ì¡°íšŒ ì‹œë„
                        df = api.get_ohlcv(code, count=10, base_dt=target_date_str)
                        if df.empty:
                            item_errors_for_date.append({
                                "code": code,
                                "error": f"{target_date_str} OHLCV ë°ì´í„° ì—†ìŒ"
                            })
                            error_stats["total_item_errors"] += 1
                            continue
                    
                    # base_dtê°€ ì§€ì •ëœ ê²½ìš°, í•´ë‹¹ ë‚ ì§œì˜ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                    if 'date' in df.columns:
                        # ë‚ ì§œ ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°, target_date_strê³¼ ì¼ì¹˜í•˜ëŠ” í–‰ ì°¾ê¸°
                        df['date_str'] = pd.to_datetime(df['date']).dt.strftime('%Y%m%d')
                        target_df = df[df['date_str'] == target_date_str]
                        if not target_df.empty:
                            future_price = float(target_df.iloc[-1]['close'])
                        else:
                            # ì •í™•í•œ ë‚ ì§œê°€ ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ í–‰ ì‚¬ìš©
                            future_price = float(df.iloc[-1]['close'])
                    else:
                        # ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ í–‰ ì‚¬ìš©
                        future_price = float(df.iloc[-1]['close'])
                    
                    return_pct = (future_price / scan_price - 1) * 100
                    
                    performance_data.append({
                        "code": code,
                        "name": item.get("name"),
                        "scan_price": scan_price,
                        "future_price": future_price,
                        "return_pct": return_pct,
                        "score": item.get("score", 0),
                        "strategy": item.get("strategy", "ê´€ì°°")
                    })
                except Exception as e:
                    # ì¢…ëª©ë³„ ì—ëŸ¬ ì¶”ì  (ìµœëŒ€ 100ê°œ)
                    if len(error_stats["item_errors"]) < 100:
                        error_stats["item_errors"].append({
                            "date": date,
                            "code": code,
                            "error": str(e)
                        })
                    error_stats["total_item_errors"] += 1
                    continue
            
            # ë‚ ì§œë³„ ì—ëŸ¬ ê¸°ë¡
            if item_errors_for_date:
                error_stats["date_errors"].append({
                    "date": date,
                    "item_errors": item_errors_for_date[:10]  # ìµœëŒ€ 10ê°œë§Œ
                })
            
            if performance_data:
                avg_return = sum(p["return_pct"] for p in performance_data) / len(performance_data)
                win_rate = sum(1 for p in performance_data if p["return_pct"] > 0) / len(performance_data) * 100
                
                performance_by_date[date] = {
                    "items_count": len(performance_data),
                    "avg_return": avg_return,
                    "win_rate": win_rate,
                    "items": performance_data
                }
        except Exception as e:
            error_stats["date_errors"].append({
                "date": date,
                "error": str(e)
            })
            continue
    
    # ì „ì²´ í†µê³„
    all_returns = []
    for perf in performance_by_date.values():
        all_returns.extend([p["return_pct"] for p in perf["items"]])
    
    overall_avg_return = sum(all_returns) / len(all_returns) if all_returns else 0
    overall_win_rate = sum(1 for r in all_returns if r > 0) / len(all_returns) * 100 if all_returns else 0
    
    return {
        "total_scans": total_scans,
        "total_items": total_items,
        "analyzed_dates": len(performance_by_date),
        "overall_avg_return": overall_avg_return,
        "overall_win_rate": overall_win_rate,
        "performance_by_date": performance_by_date,
        "errors": error_stats
    }


def print_summary(scan_results: List[Dict], performance: Dict):
    """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
    print("\n" + "=" * 80)
    print("ğŸ“Š ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 80)
    
    print(f"\nâœ… ì„±ê³µí•œ ìŠ¤ìº”: {performance['total_scans']}ê°œ")
    print(f"ğŸ“ˆ ì´ ì¶”ì²œ ì¢…ëª©: {performance['total_items']}ê°œ")
    print(f"ğŸ“… ë¶„ì„ ì™„ë£Œ ë‚ ì§œ: {performance['analyzed_dates']}ê°œ")
    
    if performance['analyzed_dates'] > 0:
        print(f"\nğŸ“Š ì „ì²´ ì„±ê³¼:")
        print(f"  í‰ê·  ìˆ˜ìµë¥ : {performance['overall_avg_return']:.2f}%")
        print(f"  ìŠ¹ë¥ : {performance['overall_win_rate']:.2f}%")
    
    # ë‚ ì§œë³„ ìƒì„¸
    if performance.get('performance_by_date'):
        print(f"\nğŸ“… ë‚ ì§œë³„ ì„±ê³¼:")
        for date, perf in sorted(performance['performance_by_date'].items()):
            print(f"  {date}: {perf['items_count']}ê°œ ì¢…ëª©, "
                  f"í‰ê·  {perf['avg_return']:.2f}%, ìŠ¹ë¥  {perf['win_rate']:.2f}%")
    
    # ì‹¤íŒ¨í•œ ìŠ¤ìº”
    failed = [r for r in scan_results if not r.get("success")]
    if failed:
        print(f"\nâŒ ì‹¤íŒ¨í•œ ìŠ¤ìº”: {len(failed)}ê°œ")
        for r in failed[:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
            print(f"  {r['date']}: {r.get('error', 'Unknown error')}")
        if len(failed) > 5:
            print(f"  ... ì™¸ {len(failed) - 5}ê°œ")
    
    # ì—ëŸ¬ í†µê³„ í‘œì‹œ
    if performance.get('errors'):
        errors = performance['errors']
        if errors.get('date_errors') or errors.get('item_errors'):
            print(f"\nâš ï¸ ì—ëŸ¬ í†µê³„:")
            print(f"  ë‚ ì§œë³„ ì—ëŸ¬: {len(errors.get('date_errors', []))}ê°œ")
            print(f"  ì¢…ëª©ë³„ ì—ëŸ¬: {errors.get('total_item_errors', 0)}ê°œ")
            if errors.get('date_errors'):
                print(f"  ë‚ ì§œë³„ ì—ëŸ¬ ìƒì„¸ (ìµœëŒ€ 5ê°œ):")
                for err in errors['date_errors'][:5]:
                    print(f"    {err.get('date', 'UNKNOWN')}: {err.get('error', 'Unknown')}")


def save_results(scan_results: List[Dict], performance: Dict, output_dir: str = "backtest_results"):
    """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ìŠ¤ìº” ê²°ê³¼ ì €ì¥
    results_file = output_path / f"scan_results_{timestamp}.json"
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(scan_results, f, ensure_ascii=False, indent=2, default=str)
    print(f"\nğŸ’¾ ìŠ¤ìº” ê²°ê³¼ ì €ì¥: {results_file}")
    
    # ì„±ê³¼ ë¶„ì„ ì €ì¥
    perf_file = output_path / f"performance_{timestamp}.json"
    with open(perf_file, 'w', encoding='utf-8') as f:
        json.dump(performance, f, ensure_ascii=False, indent=2, default=str)
    print(f"ğŸ’¾ ì„±ê³¼ ë¶„ì„ ì €ì¥: {perf_file}")
    
    # CSV ìš”ì•½ ì €ì¥
    if performance.get('performance_by_date'):
        csv_data = []
        for date, perf in sorted(performance['performance_by_date'].items()):
            csv_data.append({
                "date": date,
                "items_count": perf['items_count'],
                "avg_return": perf['avg_return'],
                "win_rate": perf['win_rate']
            })
        
        csv_file = output_path / f"performance_summary_{timestamp}.csv"
        df = pd.DataFrame(csv_data)
        df.to_csv(csv_file, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ ì„±ê³¼ ìš”ì•½ CSV ì €ì¥: {csv_file}")


def main():
    parser = argparse.ArgumentParser(description="ìŠ¤ìºë„ˆ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
    parser.add_argument(
        "--start-date",
        type=str,
        required=True,
        help="ì‹œì‘ ë‚ ì§œ (YYYYMMDD)"
    )
    parser.add_argument(
        "--end-date",
        type=str,
        required=True,
        help="ì¢…ë£Œ ë‚ ì§œ (YYYYMMDD)"
    )
    parser.add_argument(
        "--scanner-version",
        type=str,
        choices=['v1', 'v2'],
        default=None,
        help="ìŠ¤ìºë„ˆ ë²„ì „ (ê¸°ë³¸: DB ì„¤ì •)"
    )
    parser.add_argument(
        "--regime-version",
        type=str,
        choices=['v1', 'v3', 'v4'],
        default=None,
        help="ë ˆì§ ë¶„ì„ ë²„ì „ (ê¸°ë³¸: DB ì„¤ì •)"
    )
    parser.add_argument(
        "--kospi-limit",
        type=int,
        default=None,
        help="KOSPI ì¢…ëª© ìˆ˜ ì œí•œ (ê¸°ë³¸: config ê°’)"
    )
    parser.add_argument(
        "--kosdaq-limit",
        type=int,
        default=None,
        help="KOSDAQ ì¢…ëª© ìˆ˜ ì œí•œ (ê¸°ë³¸: config ê°’)"
    )
    parser.add_argument(
        "--days-after",
        type=int,
        default=5,
        help="ì„±ê³¼ ì¸¡ì • ì¼ìˆ˜ (ê¸°ë³¸: 5ì¼)"
    )
    parser.add_argument(
        "--no-cache",
        action="store_true",
        help="ìºì‹œ ì‚¬ìš© ì•ˆ í•¨"
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="backtest_results",
        help="ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: backtest_results)"
    )
    parser.add_argument(
        "--save-results",
        action="store_true",
        help="ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"
    )
    
    args = parser.parse_args()
    
    # ë‚ ì§œ ê²€ì¦
    try:
        start_date = normalize_date(args.start_date)
        end_date = normalize_date(args.end_date)
    except Exception as e:
        print(f"âŒ ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜: {e}")
        return 1
    
    # ê±°ë˜ì¼ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    trading_days = get_trading_days(start_date, end_date)
    if not trading_days:
        print(f"âŒ {start_date} ~ {end_date} ê¸°ê°„ì— ê±°ë˜ì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return 1
    
    print(f"ğŸ“… ë°±í…ŒìŠ¤íŠ¸ ê¸°ê°„: {start_date} ~ {end_date}")
    print(f"ğŸ“Š ê±°ë˜ì¼ ìˆ˜: {len(trading_days)}ê°œ")
    print(f"ğŸ”§ ìŠ¤ìºë„ˆ ë²„ì „: {args.scanner_version or 'DB ì„¤ì •'}")
    print(f"ğŸ”§ ë ˆì§ ë²„ì „: {args.regime_version or 'DB ì„¤ì •'}")
    print(f"ğŸ’¾ ìºì‹œ ì‚¬ìš©: {not args.no_cache}")
    print()
    
    # ìºì‹œ ìƒíƒœ í™•ì¸
    if not args.no_cache:
        cache_stats = api.get_ohlcv_cache_stats()
        print(f"ğŸ“¦ OHLCV ìºì‹œ ìƒíƒœ:")
        print(f"  ë©”ëª¨ë¦¬: {cache_stats.get('memory', {}).get('hits', 0)} hits, "
              f"{cache_stats.get('memory', {}).get('misses', 0)} misses")
        print(f"  ë””ìŠ¤í¬: {cache_stats.get('disk', {}).get('files', 0)} íŒŒì¼, "
              f"{cache_stats.get('disk', {}).get('size_mb', 0):.2f} MB")
        print()
    
    # ìŠ¤ìº” ì‹¤í–‰
    scan_results = []
    for i, date in enumerate(trading_days, 1):
        print(f"[{i}/{len(trading_days)}] {date} ìŠ¤ìº” ì¤‘...", end=' ', flush=True)
        
        result = run_scan_for_date(
            date=date,
            kospi_limit=args.kospi_limit,
            kosdaq_limit=args.kosdaq_limit,
            scanner_version=args.scanner_version,
            regime_version=args.regime_version,
            use_cache=not args.no_cache
        )
        
        scan_results.append(result)
        
        if result.get("success"):
            print(f"âœ… ì™„ë£Œ ({result.get('matched_count', 0)}ê°œ ì¢…ëª©)")
        else:
            print(f"âŒ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
    
    # ì„±ê³¼ ë¶„ì„
    print("\nğŸ“Š ì„±ê³¼ ë¶„ì„ ì¤‘...")
    performance = analyze_performance(scan_results, days_after=args.days_after)
    
    # ê²°ê³¼ ì¶œë ¥
    print_summary(scan_results, performance)
    
    # ìºì‹œ ìƒíƒœ í™•ì¸ (ì¢…ë£Œ)
    if not args.no_cache and cache_stats_before:
        cache_stats_after = api.get_ohlcv_cache_stats()
        print(f"\nğŸ“¦ OHLCV ìºì‹œ ìƒíƒœ (ì¢…ë£Œ):")
        print(f"  ë©”ëª¨ë¦¬: {cache_stats_after.get('memory', {}).get('hits', 0)} hits, "
              f"{cache_stats_after.get('memory', {}).get('misses', 0)} misses")
        print(f"  ë””ìŠ¤í¬: {cache_stats_after.get('disk', {}).get('files', 0)} íŒŒì¼, "
              f"{cache_stats_after.get('disk', {}).get('size_mb', 0):.2f} MB")
        
        # ìºì‹œ íˆíŠ¸ìœ¨ ê³„ì‚°
        mem_hits = cache_stats_after.get('memory', {}).get('hits', 0)
        mem_misses = cache_stats_after.get('memory', {}).get('misses', 0)
        if mem_hits + mem_misses > 0:
            hit_rate = mem_hits / (mem_hits + mem_misses) * 100
            print(f"  ìºì‹œ íˆíŠ¸ìœ¨: {hit_rate:.2f}%")
    
    # ê²°ê³¼ ì €ì¥
    if args.save_results:
        save_results(scan_results, performance, args.output_dir)
    
    return 0


if __name__ == "__main__":
    sys.exit(main())

