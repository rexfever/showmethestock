import time
from datetime import datetime
import os
from typing import List, Dict, Optional, Tuple
import requests
import pandas as pd
import numpy as np
import pickle
from pathlib import Path
import logging

from auth import KiwoomAuth
from config import config

logger = logging.getLogger(__name__)


class KiwoomAPI:
    """KIS OpenAPI v2 ë˜í¼ (ì‹¤ë°ì´í„° ê¸°ë³¸, í•„ìš” ì‹œ ëª¨ì˜ í´ë°±)"""

    def __init__(self):
        self.auth = KiwoomAuth()
        self._code_to_name: Dict[str, str] = {}
        self._name_to_code: Dict[str, str] = {}
        # OHLCV ìºì‹œ: {(code, count, base_dt, hour_key): (df, timestamp)}
        # hour_key: ì¥ì¤‘ì¼ ë•Œë§Œ ì‹œê°„ëŒ€ êµ¬ë¶„ (ì˜ˆ: "15:00"), ì¥ ë§ˆê° í›„ëŠ” None
        self._ohlcv_cache: Dict[Tuple[str, int, Optional[str], Optional[str]], Tuple[pd.DataFrame, float]] = {}
        self._cache_ttl = 300  # ê¸°ë³¸ 5ë¶„ (ì´ˆ) - ìƒí™©ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ê³„ì‚°ë¨
        self._cache_maxsize = 1000  # ìµœëŒ€ ìºì‹œ í•­ëª© ìˆ˜
        
        # ë””ìŠ¤í¬ ìºì‹œ ì„¤ì •
        self._disk_cache_dir = Path("cache/ohlcv")
        self._disk_cache_dir.mkdir(parents=True, exist_ok=True)
        self._disk_cache_enabled = True  # ë””ìŠ¤í¬ ìºì‹œ í™œì„±í™” ì—¬ë¶€
        # ëª¨ì˜ ë°ì´í„° ì„¸íŠ¸ëŠ” í•­ìƒ ì¤€ë¹„ (ì‹¤íŒ¨ ì‹œ í´ë°±ìš©)
        self._mock_kospi = [
            "005930",  # ì‚¼ì„±ì „ì
            "000660",  # SKí•˜ì´ë‹‰ìŠ¤
            "051910",  # LGí™”í•™
            "207940",  # ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤
            "005380",  # í˜„ëŒ€ì°¨
            "035420",  # NAVER
            "068270",  # ì…€íŠ¸ë¦¬ì˜¨
            "028260",  # ì‚¼ì„±ë¬¼ì‚°
            "105560",  # KBê¸ˆìœµ
            "055550",  # ì‹ í•œì§€ì£¼
        ]
        self._mock_kosdaq = [
            "091990",  # ì…€íŠ¸ë¦¬ì˜¨í—¬ìŠ¤ì¼€ì–´
            "263750",  # í„ì–´ë¹„ìŠ¤
            "035720",  # ì¹´ì¹´ì˜¤ê²Œì„ì¦ˆ
            "247540",  # ì—ì½”í”„ë¡œë¹„ì— 
            "086520",  # ì—ì½”í”„ë¡œ
            "293490",  # ì¹´ì¹´ì˜¤ë±…í¬(ì½”ìŠ¤í”¼ ì‹¤ìƒì´ë‚˜ ë°ëª¨ìš©)
        ]
        self._mock_names: Dict[str, str] = {
            "005930": "ì‚¼ì„±ì „ì",
            "000660": "SKí•˜ì´ë‹‰ìŠ¤",
            "051910": "LGí™”í•™",
            "207940": "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤",
            "005380": "í˜„ëŒ€ì°¨",
            "035420": "NAVER",
            "068270": "ì…€íŠ¸ë¦¬ì˜¨",
            "028260": "ì‚¼ì„±ë¬¼ì‚°",
            "105560": "KBê¸ˆìœµ",
            "055550": "ì‹ í•œì§€ì£¼",
            "091990": "ì…€íŠ¸ë¦¬ì˜¨í—¬ìŠ¤ì¼€ì–´",
            "263750": "í„ì–´ë¹„ìŠ¤",
            "035720": "ì¹´ì¹´ì˜¤ê²Œì„ì¦ˆ",
            "247540": "ì—ì½”í”„ë¡œë¹„ì— ",
            "086520": "ì—ì½”í”„ë¡œ",
            "293490": "ì¹´ì¹´ì˜¤ë±…í¬",
        }
        # ê°•ì œ ëª¨ì˜ ëª¨ë“œ í”Œë˜ê·¸
        self.force_mock: bool = os.getenv("FORCE_MOCK", "").lower() in ("1", "true", "yes")
        if self.force_mock:
            for code, name in self._mock_names.items():
                self._code_to_name[code] = name
                self._name_to_code[name.replace(" ", "")] = code
        # ì‹¬ë³¼ í”„ë¦¬ë¡œë“œ
        if (not self.force_mock) and config.preload_symbols:
            try:
                self._preload_symbols()
            except Exception:
                pass

    def _post(self, api_id: str, path: str, payload: dict, extra_headers: Dict[str, str] = None) -> dict:
        if self.force_mock:
            raise RuntimeError("mock mode active")
        headers = self.auth.auth_headers(api_id)
        if extra_headers:
            headers.update(extra_headers)
        url = f"{config.api_base}{path}"
        resp = requests.post(url, headers=headers, json=payload, timeout=10)
        # ë ˆì´íŠ¸ë¦¬ë°‹ ì™„ì¶©
        time.sleep(config.rate_limit_delay_ms / 1000.0)
        resp.raise_for_status()
        data = resp.json()
        # ì‘ë‹µ í—¤ë”ë¥¼ í•¨ê»˜ ì „ë‹¬(í˜ì´ì§€ë„¤ì´ì…˜ cont-yn/next-key)
        try:
            data["__headers__"] = {k.lower(): v for k, v in resp.headers.items()}
        except Exception:
            data["__headers__"] = {}
        return data

    def get_top_codes(self, market: str, limit: int) -> List[str]:
        """ê±°ë˜ëŒ€ê¸ˆ ìƒìœ„ (ì˜ˆ: ka10032) í˜¸ì¶œ í›„ ì½”ë“œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        market: 'KOSPI'|'KOSDAQ'
        """
        if self.force_mock:
            base = self._mock_kospi if market.upper() == "KOSPI" else self._mock_kosdaq
            return base[: max(0, min(len(base), limit))]
        # ì‹¤ë°ì´í„°: í™˜ê²½ì„¤ì •ì— ê³ ì • ìœ ë‹ˆë²„ìŠ¤ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
        if config.universe_codes:
            codes = [c.strip() for c in config.universe_codes.split(',') if c.strip()]
            return codes[:limit]
        # ê±°ë˜ëŒ€ê¸ˆ ìƒìœ„: ka10032 /api/dostk/krinfo
        api_id = config.kiwoom_tr_topvalue_id
        path = config.kiwoom_tr_topvalue_path
        # ka10032: mrkt_tp(001:ì½”ìŠ¤í”¼, 101:ì½”ìŠ¤ë‹¥), ê´€ë¦¬ì¢…ëª© í¬í•¨ ì—¬ë¶€, ê±°ë˜ì†Œ êµ¬ë¶„
        base_payload = {
            "mrkt_tp": "001" if market.upper() == "KOSPI" else "101",
            "mang_stk_incls": "0",
            # 1: KRX(ì½”ìŠ¤í”¼), 2: NXT(ì½”ìŠ¤ë‹¥), 3: í†µí•©
            "stex_tp": "1" if market.upper() == "KOSPI" else "2",
        }
        codes: List[str] = []
        next_key = None

        def _extract_codes(obj) -> List[str]:
            found: List[str] = []
            if isinstance(obj, dict):
                # ì½”ë“œ í›„ë³´ í‚¤
                for k in ("stk_cd", "mksc_shrn_iscd", "stck_shrn_iscd", "code"):
                    v = obj.get(k)
                    if isinstance(v, str):
                        # _NX ì ‘ë¯¸ì‚¬ ì œê±° í›„ 6ìë¦¬ ìˆ«ì í™•ì¸
                        code = v.split('_')[0]
                        if len(code) == 6 and code.isdigit():
                            found.append(code)
                # ë”•ì…”ë„ˆë¦¬ ë‚´ë¶€ ìˆœíšŒ
                for v in obj.values():
                    found.extend(_extract_codes(v))
            elif isinstance(obj, list):
                for it in obj:
                    found.extend(_extract_codes(it))
            return found

        # í˜ì´ì§€ë„¤ì´ì…˜: í—¤ë” ìš°ì„ , ë°”ë””ì˜ cont_yn/next_key ë³´ì¡°
        while len(codes) < limit:
            headers = {"cont-yn": "Y", "next-key": next_key} if next_key else {"cont-yn": "N"}
            try:
                data = self._post(api_id, path, base_payload, extra_headers=headers)
            except Exception:
                break
            # ìƒíƒœì½”ë“œê°€ ëª…ì‹œëœ ê²½ìš°ì—ë§Œ ì—ëŸ¬ë¡œ ê°„ì£¼. í‚¤ê°€ ì—†ìœ¼ë©´ í†µê³¼
            rt_cd = data.get("rt_cd")
            return_code = data.get("return_code")
            # rt_cdê°€ Noneì´ê±°ë‚˜ '0'ì´ë©´ ì •ìƒ, return_codeê°€ 0ì´ ì•„ë‹ˆë©´ ì˜¤ë¥˜
            if (rt_cd is not None and rt_cd not in ("0", 0)) or (return_code is not None and return_code not in (0, "0")):
                break
            # ì¶œë ¥ í›„ë³´ ì „ë°©ìœ„ íƒìƒ‰
            output_candidates = [
                data.get("trde_prica_upper"),
                data.get("output"),
                data.get("data"),
                data.get("list"),
            ]
            extracted: List[str] = []
            for cand in output_candidates:
                extracted.extend(_extract_codes(cand))
            # ì¤‘ë³µ ì œê±° ìˆœì„œ ìœ ì§€
            for cd in extracted:
                if cd not in codes:
                    codes.append(cd)
                    if len(codes) >= limit:
                        break

            # í˜ì´ì§€ë„¤ì´ì…˜ í‚¤ íƒìƒ‰(í—¤ë”â†’ë°”ë””)
            resp_headers = data.get("__headers__", {})
            cont = resp_headers.get("cont-yn") or str(data.get("cont_yn") or data.get("cont-yn") or "N")
            next_key = resp_headers.get("next-key") or data.get("next_key") or data.get("next-key")
            if cont != "Y" or not next_key:
                break
        # ë³´ì¡° í”Œëœ 1: .env ê³ ì • ìœ ë‹ˆë²„ìŠ¤
        if not codes and config.universe_codes:
            tmp = [c.strip() for c in config.universe_codes.split(',') if c.strip()]
            return tmp[:limit]
        # ë³´ì¡° í”Œëœ 2: ì¢…ëª©ì •ë³´(ka10099)ë¡œ ì‹œì¥ë³„ ì „ì²´ ì½”ë“œë¥¼ ë°›ì•„ ìƒìœ„ Nê°œë¡œ ëŒ€ì²´
        if not codes:
            try:
                api_id2 = config.kiwoom_tr_stockinfo_id
                path2 = config.kiwoom_tr_stockinfo_path
                headers2 = {"cont-yn": "N"}
                payload2 = {"mrkt_tp": "001" if market.upper() == "KOSPI" else "101"}
                data2 = self._post(api_id2, path2, payload2, extra_headers=headers2)
                lst = data2.get("list", []) or data2.get("output", []) or data2.get("data", [])
                found = []
                for it in lst:
                    cd = it.get("code") or it.get("mksc_shrn_iscd") or it.get("stck_shrn_iscd") or it.get("stk_cd")
                    if isinstance(cd, str) and len(cd) == 6 and cd.isdigit():
                        found.append(cd)
                if found:
                    return found[:limit]
            except Exception:
                pass
        if not codes and config.use_mock_fallback:
            base = self._mock_kospi if market.upper() == "KOSPI" else self._mock_kosdaq
            return base[: max(0, min(len(base), limit))]
        return codes[:limit]

    # ë””ë²„ê·¸ìš©: ê±°ë˜ëŒ€ê¸ˆ ìƒìœ„ TR(ka10032) 1íšŒ í˜¸ì¶œ ì›ì‹œ ì‘ë‹µ ë°˜í™˜
    def debug_call_topvalue_once(self, market: str) -> dict:
        if self.force_mock:
            return {"mock": True, "codes": self._mock_kospi if market.upper()=="KOSPI" else self._mock_kosdaq}
        api_id = config.kiwoom_tr_topvalue_id
        path = config.kiwoom_tr_topvalue_path
        payload = {
            "mrkt_tp": "001" if market.upper()=="KOSPI" else "101",
            "mang_stk_incls": "0",
            "stex_tp": "1",
        }
        try:
            return self._post(api_id, path, payload, extra_headers={"cont-yn": "N"})
        except Exception as e:
            return {"error": str(e)}

    # ë””ë²„ê·¸ìš©: ì¢…ëª©ì •ë³´ TR(ka10099) 1íšŒ í˜¸ì¶œ ì›ì‹œ ì‘ë‹µ ë°˜í™˜
    def debug_call_stockinfo_once(self, market_tp: str = '001') -> dict:
        if self.force_mock:
            return {"mock": True, "market_tp": market_tp}
        api_id = config.kiwoom_tr_stockinfo_id
        path = config.kiwoom_tr_stockinfo_path
        try:
            return self._post(api_id, path, {"mrkt_tp": market_tp}, extra_headers={"cont-yn": "Y"})
        except Exception as e:
            return {"error": str(e)}

    def _preload_symbols(self) -> None:
        markets = [m.strip() for m in config.kiwoom_symbol_markets.split(',') if m.strip()]
        for m in markets:
            api_id = config.kiwoom_tr_stockinfo_id
            path = config.kiwoom_tr_stockinfo_path
            next_key = None
            while True:
                headers = {"cont-yn": "Y", "next-key": next_key} if next_key else {"cont-yn": "N"}
                payload = {"mrkt_tp": m}
                data = self._post(api_id, path, payload, extra_headers=headers)
                rt = data.get("rt_cd"); rc = data.get("return_code")
                if (rt is not None and rt not in ("0", 0)) or (rc is not None and rc not in (0, "0")):
                    break
                lst = data.get("list", []) or data.get("output", []) or data.get("data", [])
                for it in lst:
                    cd = it.get("code") or it.get("mksc_shrn_iscd") or it.get("stck_shrn_iscd")
                    nm = it.get("name") or it.get("prdt_abrv_name")
                    if cd and nm:
                        self._code_to_name[cd] = nm
                        self._name_to_code[nm.replace(" ", "")] = cd
                h = data.get("__headers__", {})
                if h.get("cont-yn") != "Y" or not h.get("next-key"):
                    break
                next_key = h.get("next-key")

    def _get_cache_key(self, code: str, count: int, base_dt: Optional[str]) -> Tuple[str, int, Optional[str], Optional[str]]:
        """ìºì‹œ í‚¤ ìƒì„±
        
        base_dtê°€ Noneì¸ ê²½ìš°, ì‹œê°„ëŒ€ë³„ë¡œ êµ¬ë¶„í•˜ì—¬ ìºì‹±
        - 08:00 ~ 20:00: ì‹œê°„ë³„ êµ¬ë¶„ (ì• í”„í„°ë§ˆì¼“ í¬í•¨, ì£¼ê°€ ë³€ë™ ê°€ëŠ¥)
        - 20:00 ~ 08:00: ë‹¹ì¼ë¡œ í†µí•© (ë°ì´í„° ë³€ê²½ ì—†ìŒ)
        """
        # base_dtê°€ Noneì¸ ê²½ìš°
        if base_dt is None:
            from datetime import datetime
            import pytz
            KST = pytz.timezone('Asia/Seoul')
            now = datetime.now(KST)
            hour = now.hour
            
            # 08:00 ~ 20:00: ì‹œê°„ëŒ€ë³„ êµ¬ë¶„ (ì• í”„í„°ë§ˆì¼“ í¬í•¨)
            if 8 <= hour < 20:
                hour_key = f"{now.hour:02d}:{now.minute // 10 * 10:02d}"  # 10ë¶„ ë‹¨ìœ„
                return (code, count, base_dt, hour_key)
            # 20:00 ~ 08:00: ë‹¹ì¼ë¡œ í†µí•©
            else:
                return (code, count, base_dt, None)
        
        # base_dtê°€ ëª…ì‹œëœ ê²½ìš°: ë‚ ì§œë§Œ ì‚¬ìš©
        return (code, count, base_dt, None)
    
    def _calculate_ttl(self, base_dt: Optional[str]) -> int:
        """ìƒí™©ì— ë§ëŠ” TTL ê³„ì‚°
        
        - ê³¼ê±° ë‚ ì§œ: 1ë…„ (ë³€ê²½ë˜ì§€ ì•ŠìŒ)
        - ì¥ì¤‘: 1ë¶„ (ì‹¤ì‹œê°„ì„± í•„ìš”)
        - ì¥ ë§ˆê° í›„: 24ì‹œê°„ (ë‹¤ìŒ ê±°ë˜ì¼ê¹Œì§€)
        """
        if base_dt:
            try:
                from datetime import datetime
                base_date = datetime.strptime(base_dt, "%Y%m%d").date()
                now_date = datetime.now().date()
                if base_date < now_date:
                    # ê³¼ê±° ë‚ ì§œ: 1ë…„ ìºì‹±
                    return 365 * 24 * 3600
            except:
                pass
        
        # í˜„ì¬ ë‚ ì§œ: ì‹œê°„ëŒ€ì— ë”°ë¼
        from datetime import datetime
        import pytz
        KST = pytz.timezone('Asia/Seoul')
        now = datetime.now(KST)
        hour = now.hour
        
        # 08:00 ~ 20:00: ì• í”„í„°ë§ˆì¼“ í¬í•¨, ì£¼ê°€ ë³€ë™ ê°€ëŠ¥
        if 8 <= hour < 20:
            return 60  # 1ë¶„
        # 20:00 ~ 08:00: ë°ì´í„° ë³€ê²½ ì—†ìŒ
        else:
            return self._get_ttl_until_next_trading_day()
    
    def _get_ttl_until_next_trading_day(self) -> int:
        """ë‹¤ìŒ ê±°ë˜ì¼ ì‹œì‘ ì „ê¹Œì§€ì˜ TTL ê³„ì‚°"""
        from datetime import datetime, timedelta
        import pytz
        
        KST = pytz.timezone('Asia/Seoul')
        now = datetime.now(KST)
        
        # ë‹¤ìŒ ê±°ë˜ì¼ ì°¾ê¸°
        next_date = now.date() + timedelta(days=1)
        
        # ê³µíœ´ì¼ ì²´í¬ (holidays ëª¨ë“ˆì´ ìˆìœ¼ë©´ ì‚¬ìš©)
        try:
            import holidays
            kr_holidays = holidays.SouthKorea()
            # ì£¼ë§ê³¼ ê³µíœ´ì¼ ì œì™¸
            while next_date.weekday() >= 5 or next_date in kr_holidays:
                next_date += timedelta(days=1)
        except ImportError:
            # holidays ëª¨ë“ˆì´ ì—†ìœ¼ë©´ ì£¼ë§ë§Œ ì²´í¬
            while next_date.weekday() >= 5:
                next_date += timedelta(days=1)
        
        # ë‹¤ìŒ ê±°ë˜ì¼ 09:00ê¹Œì§€ì˜ ì‹œê°„ ê³„ì‚°
        next_trading_day_start = KST.localize(
            datetime.combine(next_date, datetime.min.time().replace(hour=9))
        )
        
        # í˜„ì¬ ì‹œê°„ë¶€í„° ë‹¤ìŒ ê±°ë˜ì¼ 09:00ê¹Œì§€ì˜ ì´ˆ
        ttl_seconds = int((next_trading_day_start - now).total_seconds())
        
        # ìµœì†Œ 1ì‹œê°„, ìµœëŒ€ 72ì‹œê°„ (ì£¼ë§ ê±´ë„ˆë›°ëŠ” ê²½ìš°)
        return max(3600, min(ttl_seconds, 72 * 3600))
    
    def _is_market_open(self) -> bool:
        """ì¥ì¤‘ ì—¬ë¶€ í™•ì¸ (09:00 ~ 15:30, í‰ì¼ë§Œ)"""
        from datetime import datetime
        import pytz
        
        KST = pytz.timezone('Asia/Seoul')
        now = datetime.now(KST)
        
        # ì£¼ë§ ì œì™¸
        if now.weekday() >= 5:  # í† ìš”ì¼(5), ì¼ìš”ì¼(6)
            return False
        
        hour = now.hour
        minute = now.minute
        
        # ì¥ì¤‘: 09:00 ~ 15:30
        return (9 <= hour < 15) or (hour == 15 and minute <= 30)
    
    def _is_aftermarket_hours(self) -> bool:
        """ì• í”„í„°ë§ˆì¼“ ì‹œê°„ëŒ€ í™•ì¸ (08:00 ~ 20:00)"""
        from datetime import datetime
        import pytz
        
        KST = pytz.timezone('Asia/Seoul')
        now = datetime.now(KST)
        hour = now.hour
        
        # ì• í”„í„°ë§ˆì¼“: 08:00 ~ 20:00 (ì¥ì „ ì‹œê°„ì™¸ + ì¥ì¤‘ + ì¥í›„ ì‹œê°„ì™¸)
        return 8 <= hour < 20
    
    def _get_cached_ohlcv(self, code: str, count: int, base_dt: Optional[str]) -> Optional[pd.DataFrame]:
        """ìºì‹œì—ì„œ OHLCV ë°ì´í„° ì¡°íšŒ"""
        cache_key = self._get_cache_key(code, count, base_dt)
        
        if cache_key not in self._ohlcv_cache:
            return None
        
        cached_df, timestamp = self._ohlcv_cache[cache_key]
        
        # base_dtê°€ Noneì¸ ê²½ìš°, DataFrameì˜ ì‹¤ì œ ë‚ ì§œ í™•ì¸
        actual_date = base_dt
        if actual_date is None and not cached_df.empty and 'date' in cached_df.columns:
            try:
                # DataFrameì˜ ë§ˆì§€ë§‰ ë‚ ì§œ ì¶”ì¶œ
                last_date_str = str(cached_df.iloc[-1]['date'])
                # YYYYMMDD í˜•ì‹ì¸ì§€ í™•ì¸
                if len(last_date_str) == 8 and last_date_str.isdigit():
                    actual_date = last_date_str
            except:
                pass
        
        # ì‹¤ì œ ë‚ ì§œë¥¼ ì‚¬ìš©í•˜ì—¬ TTL ê³„ì‚°
        ttl = self._calculate_ttl(actual_date)
        
        # TTL í™•ì¸
        if time.time() - timestamp > ttl:
            del self._ohlcv_cache[cache_key]
            return None
        
        # ë³µì‚¬ë³¸ ë°˜í™˜ (ì›ë³¸ ë°ì´í„° ë³´í˜¸)
        return cached_df.copy()
    
    def _set_cached_ohlcv(self, code: str, count: int, base_dt: Optional[str], df: pd.DataFrame) -> None:
        """OHLCV ë°ì´í„°ë¥¼ ìºì‹œì— ì €ì¥"""
        if df.empty:
            return
        
        cache_key = self._get_cache_key(code, count, base_dt)
        
        # ìºì‹œ í¬ê¸° ì œí•œ (LRU ë°©ì‹)
        if len(self._ohlcv_cache) >= self._cache_maxsize:
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
            oldest_key = min(self._ohlcv_cache.items(), key=lambda x: x[1][1])[0]
            del self._ohlcv_cache[oldest_key]
        
        # ìºì‹œ ì €ì¥ (ë³µì‚¬ë³¸ ì €ì¥)
        self._ohlcv_cache[cache_key] = (df.copy(), time.time())
    
    def clear_ohlcv_cache(self, code: str = None) -> None:
        """OHLCV ìºì‹œ í´ë¦¬ì–´
        
        Args:
            code: íŠ¹ì • ì¢…ëª© ì½”ë“œ (Noneì´ë©´ ì „ì²´ ìºì‹œ í´ë¦¬ì–´)
        """
        # ë©”ëª¨ë¦¬ ìºì‹œ í´ë¦¬ì–´
        if code is None:
            self._ohlcv_cache.clear()
        else:
            # íŠ¹ì • ì¢…ëª©ì˜ ëª¨ë“  ìºì‹œ í•­ëª© ì œê±°
            keys_to_remove = [
                key for key in self._ohlcv_cache.keys()
                if key[0] == code  # key[0] = code
            ]
            for key in keys_to_remove:
                del self._ohlcv_cache[key]
        
        # ë””ìŠ¤í¬ ìºì‹œ í´ë¦¬ì–´
        if code is None:
            # ì „ì²´ ë””ìŠ¤í¬ ìºì‹œ ì‚­ì œ
            for cache_file in self._disk_cache_dir.glob("*.pkl"):
                cache_file.unlink()
        else:
            # íŠ¹ì • ì¢…ëª©ì˜ ë””ìŠ¤í¬ ìºì‹œ ì‚­ì œ
            pattern = f"{code}_*.pkl"
            for cache_file in self._disk_cache_dir.glob(pattern):
                cache_file.unlink()
    
    def get_ohlcv_cache_stats(self) -> Dict:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        current_time = time.time()
        valid_count = sum(
            1 for _, (_, timestamp) in self._ohlcv_cache.items()
            if current_time - timestamp <= self._cache_ttl
        )
        expired_count = len(self._ohlcv_cache) - valid_count
        
        # ë””ìŠ¤í¬ ìºì‹œ í†µê³„
        disk_cache_files = list(self._disk_cache_dir.glob("*.pkl")) if self._disk_cache_enabled else []
        disk_cache_size = sum(f.stat().st_size for f in disk_cache_files) if disk_cache_files else 0
        
        # ê¸°ì¡´ í˜•ì‹ ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)
        stats = {
            "total": len(self._ohlcv_cache),
            "valid": valid_count,
            "expired": expired_count,
            "maxsize": self._cache_maxsize,
            "ttl": self._cache_ttl,
            # ë””ìŠ¤í¬ ìºì‹œ ì •ë³´ ì¶”ê°€
            "disk": {
                "enabled": self._disk_cache_enabled,
                "total_files": len(disk_cache_files),
                "total_size_bytes": disk_cache_size,
                "total_size_mb": round(disk_cache_size / (1024 * 1024), 2),
                "cache_dir": str(self._disk_cache_dir)
            }
        }
        
        return stats
    
    def get_ohlcv(self, code: str, count: int = 220, base_dt: str = None) -> pd.DataFrame:
        """ì¼ë´‰ OHLCV DataFrame(date, open, high, low, close, volume) ë°˜í™˜
        base_dtê°€ ì§€ì •ë˜ë©´ í•´ë‹¹ ê¸°ì¤€ì¼ì„ ë§ˆì§€ë§‰ í–‰ìœ¼ë¡œ í•˜ëŠ” ì‹œê³„ì—´ì„ ìš°ì„  ì‹œë„í•œë‹¤(YYYYMMDD).
        
        ìºì‹± ì ìš©:
        - ë©”ëª¨ë¦¬ ìºì‹œ ìš°ì„  í™•ì¸
        - base_dtê°€ ìˆëŠ” ê²½ìš°: í•´ë‹¹ base_dtì˜ ë””ìŠ¤í¬ ìºì‹œ í™•ì¸
        - base_dtê°€ Noneì¸ ê²½ìš°: ìµœì‹  ë””ìŠ¤í¬ ìºì‹œ í™•ì¸ í›„ ì¦ë¶„ ì—…ë°ì´íŠ¸
        - ìºì‹œ ë¯¸ìŠ¤ ì‹œ API í˜¸ì¶œ í›„ ë©”ëª¨ë¦¬ + ë””ìŠ¤í¬ ì €ì¥
        """
        # 1. ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
        cached_df = self._get_cached_ohlcv(code, count, base_dt)
        if cached_df is not None:
            return cached_df
        
        # 2. ë””ìŠ¤í¬ ìºì‹œ í™•ì¸
        if self._disk_cache_enabled:
            if base_dt:
                # base_dtê°€ ì§€ì •ëœ ê²½ìš°: í•´ë‹¹ base_dtì˜ ìºì‹œ í™•ì¸
                cached_df = self._load_from_disk_cache(code, count, base_dt)
                if cached_df is not None:
                    # ë©”ëª¨ë¦¬ ìºì‹œì—ë„ ì €ì¥
                    self._set_cached_ohlcv(code, count, base_dt, cached_df)
                    return cached_df
            else:
                # base_dtê°€ Noneì¸ ê²½ìš°: ìµœì‹  ë””ìŠ¤í¬ ìºì‹œ ì°¾ì•„ì„œ ì¦ë¶„ ì—…ë°ì´íŠ¸
                cached_df, latest_base_dt = self._find_latest_disk_cache(code, count)
                if cached_df is not None:
                    # ìºì‹œì˜ ìµœì‹  ë‚ ì§œ í™•ì¸
                    if 'date' in cached_df.columns:
                        cached_df['date'] = pd.to_datetime(cached_df['date'])
                        latest_cache_date = cached_df['date'].max()
                    else:
                        # dateê°€ ì¸ë±ìŠ¤ì¸ ê²½ìš°
                        if isinstance(cached_df.index, pd.DatetimeIndex):
                            latest_cache_date = cached_df.index.max()
                        else:
                            latest_cache_date = None
                    
                    # ì˜¤ëŠ˜ ë‚ ì§œ
                    today = pd.Timestamp.now().normalize()
                    
                    # ìºì‹œì˜ ìµœì‹  ë‚ ì§œê°€ ì˜¤ëŠ˜ë³´ë‹¤ ì˜¤ë˜ëœ ê²½ìš°ì—ë§Œ ë‹¹ì¼ ë°ì´í„° ì¶”ê°€
                    if latest_cache_date is not None and latest_cache_date < today:
                        logger.debug(f"{code} ìºì‹œê°€ ì˜¤ë˜ë¨ (ìµœì‹ : {latest_cache_date.date()}, ì˜¤ëŠ˜: {today.date()}), ë‹¹ì¼ ë°ì´í„° ì¶”ê°€")
                        # ë‹¹ì¼ ë°ì´í„°ë§Œ APIë¡œ ê°€ì ¸ì˜¤ê¸°
                        today_data = self._fetch_today_data_from_api(code)
                        if not today_data.empty:
                            # ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©
                            combined = pd.concat([cached_df, today_data])
                            # ì¤‘ë³µ ì œê±° (ìµœì‹  ë°ì´í„° ìš°ì„ )
                            if 'date' in combined.columns:
                                combined = combined.drop_duplicates(subset=['date'], keep='last')
                                combined = combined.sort_values('date').reset_index(drop=True)
                            else:
                                combined = combined[~combined.index.duplicated(keep='last')]
                                combined = combined.sort_index()
                            
                            # countë§Œí¼ë§Œ ë°˜í™˜
                            if len(combined) > count:
                                combined = combined.tail(count)
                            
                            # ë©”ëª¨ë¦¬ ìºì‹œ ì €ì¥
                            self._set_cached_ohlcv(code, count, base_dt, combined)
                            
                            # ë””ìŠ¤í¬ ìºì‹œ ì—…ë°ì´íŠ¸
                            # combinedì˜ ìµœì‹  ë‚ ì§œë¥¼ base_dtë¡œ ì‚¬ìš©
                            if 'date' in combined.columns:
                                combined_latest_date = pd.to_datetime(combined['date']).max()
                            elif isinstance(combined.index, pd.DatetimeIndex):
                                combined_latest_date = combined.index.max()
                            else:
                                combined_latest_date = None
                            
                            if combined_latest_date is not None:
                                # ê³¼ê±° ë‚ ì§œì¸ ê²½ìš°ë§Œ ë””ìŠ¤í¬ ìºì‹œ ì €ì¥
                                today = pd.Timestamp.now().normalize()
                                if combined_latest_date < today:
                                    combined_base_dt = combined_latest_date.strftime('%Y%m%d')
                                    self._save_to_disk_cache(code, count, combined_base_dt, combined)
                            
                            return combined
                    
                    # ìºì‹œê°€ ìµœì‹ ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
                    if len(cached_df) >= count:
                        result = cached_df.tail(count)
                        # ë©”ëª¨ë¦¬ ìºì‹œì—ë„ ì €ì¥
                        self._set_cached_ohlcv(code, count, base_dt, result)
                        return result
        
        # 3. ìºì‹œ ë¯¸ìŠ¤: API í˜¸ì¶œ
        if self.force_mock:
            df = self._gen_mock_ohlcv(code, count, base_dt)
        else:
            try:
                df = self._fetch_ohlcv_from_api(code, count, base_dt)
            except RuntimeError as e:
                # í‚¤ì›€ API ì¸ì¦ ì‹¤íŒ¨ ì‹œ ë””ìŠ¤í¬ ìºì‹œ ì¬ì‹œë„
                if "ì¸ì¦ì— ì‹¤íŒ¨" in str(e) or "Token error" in str(e):
                    logger.warning(f"í‚¤ì›€ API ì¸ì¦ ì‹¤íŒ¨, ë””ìŠ¤í¬ ìºì‹œ ì¬ì‹œë„: {code}")
                    if base_dt and self._disk_cache_enabled:
                        # base_dtê°€ ìˆëŠ” ê²½ìš°: í•´ë‹¹ base_dtì˜ ìºì‹œ ì¬ì‹œë„
                        cached_df = self._load_from_disk_cache(code, count, base_dt)
                        if cached_df is not None and not cached_df.empty:
                            logger.info(f"ë””ìŠ¤í¬ ìºì‹œì—ì„œ ë¡œë“œ ì„±ê³µ: {code}, {base_dt}")
                            self._set_cached_ohlcv(code, count, base_dt, cached_df)
                            return cached_df
                    # base_dtê°€ Noneì¸ ê²½ìš°: ìµœì‹  ë””ìŠ¤í¬ ìºì‹œ ì¬ì‹œë„
                    if not base_dt and self._disk_cache_enabled:
                        cached_df, _ = self._find_latest_disk_cache(code, count)
                        if cached_df is not None and not cached_df.empty:
                            logger.info(f"ìµœì‹  ë””ìŠ¤í¬ ìºì‹œì—ì„œ ë¡œë“œ ì„±ê³µ: {code}")
                            result = cached_df.tail(count) if len(cached_df) >= count else cached_df
                            self._set_cached_ohlcv(code, count, base_dt, result)
                            return result
                    logger.error(f"ë””ìŠ¤í¬ ìºì‹œë„ ì—†ìŒ, API ì¸ì¦ ì‹¤íŒ¨: {code}, {e}")
                raise
        
        # 4. ìºì‹œ ì €ì¥ (ë©”ëª¨ë¦¬ + ë””ìŠ¤í¬)
        if not df.empty:
            self._set_cached_ohlcv(code, count, base_dt, df)
            # base_dtê°€ ìˆëŠ” ê²½ìš° ë””ìŠ¤í¬ì—ë„ ì €ì¥ (ê³¼ê±° ë‚ ì§œ)
            if base_dt and self._disk_cache_enabled:
                self._save_to_disk_cache(code, count, base_dt, df)
            elif base_dt is None and self._disk_cache_enabled:
                # base_dtê°€ Noneì¸ ê²½ìš°: DataFrameì˜ ìµœì‹  ë‚ ì§œë¥¼ base_dtë¡œ ì‚¬ìš©
                if 'date' in df.columns:
                    latest_date = pd.to_datetime(df['date']).max()
                elif isinstance(df.index, pd.DatetimeIndex):
                    latest_date = df.index.max()
                else:
                    latest_date = None
                
                if latest_date is not None:
                    # ê³¼ê±° ë‚ ì§œì¸ ê²½ìš°ë§Œ ë””ìŠ¤í¬ ìºì‹œ ì €ì¥
                    today = pd.Timestamp.now().normalize()
                    if latest_date < today:
                        base_dt_str = latest_date.strftime('%Y%m%d')
                        self._save_to_disk_cache(code, count, base_dt_str, df)
        
        return df
    
    def _get_disk_cache_file_path(self, code: str, count: int, base_dt: str) -> Path:
        """ë””ìŠ¤í¬ ìºì‹œ íŒŒì¼ ê²½ë¡œ ìƒì„±
        
        Args:
            code: ì¢…ëª© ì½”ë“œ
            count: ë°ì´í„° ê°œìˆ˜
            base_dt: ê¸°ì¤€ì¼ (YYYYMMDD)
        
        Returns:
            ìºì‹œ íŒŒì¼ ê²½ë¡œ
        """
        # íŒŒì¼ëª…: {code}_{count}_{base_dt}.pkl
        filename = f"{code}_{count}_{base_dt}.pkl"
        return self._disk_cache_dir / filename
    
    def _load_from_disk_cache(self, code: str, count: int, base_dt: str) -> Optional[pd.DataFrame]:
        """ë””ìŠ¤í¬ ìºì‹œì—ì„œ OHLCV ë°ì´í„° ë¡œë“œ
        
        Args:
            code: ì¢…ëª© ì½”ë“œ
            count: ë°ì´í„° ê°œìˆ˜
            base_dt: ê¸°ì¤€ì¼ (YYYYMMDD)
        
        Returns:
            DataFrame ë˜ëŠ” None (ìºì‹œ ì—†ìŒ/ë§Œë£Œ)
        """
        if not self._disk_cache_enabled:
            return None
        
        cache_file = self._get_disk_cache_file_path(code, count, base_dt)
        
        if not cache_file.exists():
            return None
        
        try:
            # íŒŒì¼ì—ì„œ ë¡œë“œ
            with open(cache_file, 'rb') as f:
                cached_data = pickle.load(f)
                df, timestamp = cached_data
            
            # TTL í™•ì¸ (ê³¼ê±° ë‚ ì§œëŠ” 1ë…„)
            ttl = self._calculate_ttl(base_dt)
            if time.time() - timestamp > ttl:
                # ë§Œë£Œëœ ìºì‹œ ì‚­ì œ
                cache_file.unlink()
                return None
            
            # ë³µì‚¬ë³¸ ë°˜í™˜
            return df.copy()
        except Exception as e:
            # ë¡œë“œ ì‹¤íŒ¨ ì‹œ íŒŒì¼ ì‚­ì œ
            try:
                cache_file.unlink()
            except:
                pass
            return None
    
    def _find_latest_disk_cache(self, code: str, count: int) -> Tuple[Optional[pd.DataFrame], Optional[str]]:
        """ìµœì‹  ë””ìŠ¤í¬ ìºì‹œ ì°¾ê¸° (base_dt=Noneì¼ ë•Œ ì‚¬ìš©)
        
        Args:
            code: ì¢…ëª© ì½”ë“œ
            count: ë°ì´í„° ê°œìˆ˜
        
        Returns:
            (DataFrame, base_dt) ë˜ëŠ” (None, None)
        """
        if not self._disk_cache_enabled:
            return None, None
        
        try:
            # ìºì‹œ ë””ë ‰í† ë¦¬ì—ì„œ í•´ë‹¹ ì¢…ëª©ì˜ ëª¨ë“  ìºì‹œ íŒŒì¼ ì°¾ê¸°
            pattern = f"{code}_{count}_*.pkl"
            cache_files = list(self._disk_cache_dir.glob(pattern))
            
            if not cache_files:
                return None, None
            
            # base_dt ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìµœì‹  ë‚ ì§œ ìš°ì„ )
            cache_files_with_dt = []
            for cache_file in cache_files:
                try:
                    # íŒŒì¼ëª…ì—ì„œ base_dt ì¶”ì¶œ: {code}_{count}_{base_dt}.pkl
                    base_dt = cache_file.stem.split('_')[-1]
                    if len(base_dt) == 8 and base_dt.isdigit():
                        cache_files_with_dt.append((cache_file, base_dt))
                except:
                    continue
            
            if not cache_files_with_dt:
                return None, None
            
            # base_dt ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (ìµœì‹  ë‚ ì§œ ìš°ì„ )
            cache_files_with_dt.sort(key=lambda x: x[1], reverse=True)
            
            # ìµœì‹  ìºì‹œ íŒŒì¼ ë¡œë“œ ì‹œë„
            for cache_file, base_dt in cache_files_with_dt:
                try:
                    with open(cache_file, 'rb') as f:
                        cached_data = pickle.load(f)
                        df, timestamp = cached_data
                    
                    # TTL í™•ì¸ (ê³¼ê±° ë‚ ì§œëŠ” 1ë…„)
                    ttl = self._calculate_ttl(base_dt)
                    if time.time() - timestamp > ttl:
                        # ë§Œë£Œëœ ìºì‹œëŠ” ê±´ë„ˆë›°ê¸°
                        continue
                    
                    # ë³µì‚¬ë³¸ ë°˜í™˜
                    return df.copy(), base_dt
                except Exception as e:
                    logger.debug(f"{code} ìºì‹œ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {cache_file}, {e}")
                    continue
            
            return None, None
        except Exception as e:
            logger.debug(f"{code} ìµœì‹  ìºì‹œ ì°¾ê¸° ì‹¤íŒ¨: {e}")
            return None, None
    
    def _fetch_today_data_from_api(self, code: str) -> pd.DataFrame:
        """ë‹¹ì¼ ë°ì´í„°ë§Œ APIë¡œ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            code: ì¢…ëª© ì½”ë“œ
        
        Returns:
            DataFrame (ë‹¹ì¼ ë°ì´í„°ë§Œ, ë¹„ì–´ìˆì„ ìˆ˜ ìˆìŒ)
        """
        try:
            # ìµœê·¼ 5ì¼ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ë‹¹ì¼ ë°ì´í„°ë§Œ í•„í„°ë§
            df = self._fetch_ohlcv_from_api(code, count=5, base_dt=None)
            if df.empty:
                return df
            
            # ì˜¤ëŠ˜ ë‚ ì§œ
            today = pd.Timestamp.now().normalize()
            
            # date ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'])
                today_df = df[df['date'].dt.normalize() == today]
            # dateê°€ ì¸ë±ìŠ¤ì¸ ê²½ìš°
            elif isinstance(df.index, pd.DatetimeIndex):
                today_df = df[df.index.normalize() == today]
            else:
                # date ì •ë³´ê°€ ì—†ìœ¼ë©´ ë¹ˆ DataFrame ë°˜í™˜
                return pd.DataFrame()
            
            return today_df
        except Exception as e:
            logger.warning(f"{code} ë‹¹ì¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def _save_to_disk_cache(self, code: str, count: int, base_dt: str, df: pd.DataFrame) -> None:
        """ë””ìŠ¤í¬ ìºì‹œì— OHLCV ë°ì´í„° ì €ì¥
        
        Args:
            code: ì¢…ëª© ì½”ë“œ
            count: ë°ì´í„° ê°œìˆ˜
            base_dt: ê¸°ì¤€ì¼ (YYYYMMDD)
            df: DataFrame
        """
        if not self._disk_cache_enabled or df.empty:
            return
        
        # base_dtê°€ ê³¼ê±° ë‚ ì§œì¸ ê²½ìš°ë§Œ ë””ìŠ¤í¬ ìºì‹œ ì €ì¥
        try:
            from datetime import datetime
            base_date = datetime.strptime(base_dt, "%Y%m%d").date()
            now_date = datetime.now().date()
            
            # í˜„ì¬ ë‚ ì§œ ë˜ëŠ” ë¯¸ë˜ ë‚ ì§œëŠ” ë””ìŠ¤í¬ ìºì‹œ ì €ì¥ ì•ˆ í•¨
            if base_date >= now_date:
                return
        except:
            # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì €ì¥ ì•ˆ í•¨
            return
        
        cache_file = self._get_disk_cache_file_path(code, count, base_dt)
        
        try:
            # ë””ë ‰í† ë¦¬ ìƒì„± (ì´ë¯¸ ìˆì§€ë§Œ ì•ˆì „ì„ ìœ„í•´)
            cache_file.parent.mkdir(parents=True, exist_ok=True)
            
            # íŒŒì¼ì— ì €ì¥
            with open(cache_file, 'wb') as f:
                pickle.dump((df.copy(), time.time()), f)
        except Exception:
            # ì €ì¥ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰ (ë””ìŠ¤í¬ ë¬¸ì œ ë“±)
            pass
    
    def _fetch_ohlcv_from_api(self, code: str, count: int = 220, base_dt: str = None) -> pd.DataFrame:
        """APIì—ì„œ OHLCV ë°ì´í„°ë¥¼ ì§ì ‘ ê°€ì ¸ì˜¤ê¸° (ìºì‹± ì—†ìŒ)"""
        api_id = config.kiwoom_tr_ohlcv_id
        path = config.kiwoom_tr_ohlcv_path
        # ka10081: stk_cd, base_dt(YYYYMMDD), upd_stkpc_tp(0|1)
        # ìƒ˜í”Œ ìŠ¤í™ì— ë”°ë¼ ì ‘ë‘ì‚¬ ì—†ì´ 6ìë¦¬ ì½”ë“œë¥¼ ê¸°ë³¸ ì‚¬ìš©.
        # 1ì°¨: base_dt ë¯¸ì§€ì •(ì„œë²„ ê¸°ë³¸) â†’ 2ì°¨: ì§ì „ ì˜ì—…ì¼ ì¬ì‹œë„
        def _request(bdt: str) -> list:
            payload = {"stk_cd": code, "base_dt": bdt or "", "upd_stkpc_tp": "1"}
            d = self._post(api_id, path, payload)
            if d.get("rt_cd") not in ("0", 0) and d.get("return_code") not in (0, "0"):
                return []
            return d.get("stk_dt_pole_chart_qry", []) or d.get("output2", []) or d.get("data", [])

        # ìš°ì„ ìˆœìœ„: ëª…ì‹œ base_dt â†’ (ê¸°ì¤€ì¼-1B) â†’ (ê¸°ì¤€ì¼-2B) ... â†’ ì˜¤ëŠ˜/ì „ì˜ì—…ì¼
        tried = False
        rows = []
        if base_dt:
            try:
                rows = _request(base_dt)
                tried = True
            except Exception:
                rows = []
            # ê¸°ì¤€ì¼ë¡œë¶€í„° ì´ì „ ì˜ì—…ì¼ ë‹¤ì¤‘ ì¬ì‹œë„(ìµœëŒ€ 4)
            if not rows:
                try:
                    base_ts = pd.to_datetime(base_dt)
                    for i in range(1, 5):
                        prev = (base_ts - pd.tseries.offsets.BDay(i)).strftime("%Y%m%d")
                        rows = _request(prev)
                        if rows:
                            break
                except Exception:
                    rows = []
        # ê¸°ì¤€ì¼ ë£¨íŠ¸ì—ì„œë„ ì‹¤íŒ¨í•˜ë©´ ì˜¤ëŠ˜/ì „ì˜ì—…ì¼ë¡œ ë³´ì¡° ì‹œë„
        if not rows:
            rows = _request("")
        if not rows:
            prev = pd.bdate_range(end=pd.Timestamp.today(), periods=2)[0]
            rows = _request(prev.strftime("%Y%m%d"))
        # API ì‘ë‹µ ë””ë²„ê¹…: ì‹¤ì œ ì‘ë‹µ êµ¬ì¡° í™•ì¸ (high/lowê°€ 0ì¸ ê²½ìš°)
        # ë””ë²„ê¹… í”Œë˜ê·¸ê°€ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ ë¡œê¹…
        if rows and len(rows) > 0 and os.getenv("DEBUG_API_RESPONSE") == "1":
            sample_row = rows[0]
            print(f"ğŸ” API ì‘ë‹µ ë””ë²„ê¹… (ì½”ë“œ: {code}):")
            print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  í‚¤: {list(sample_row.keys())}")
            high_candidates = {k: sample_row.get(k) for k in ["high_prc", "hg_prc", "high", "stck_hgpr"] if k in sample_row}
            if high_candidates:
                print(f"   high í›„ë³´ í•„ë“œ: {high_candidates}")
            low_candidates = {k: sample_row.get(k) for k in ["low_prc", "lw_prc", "low", "stck_lwpr"] if k in sample_row}
            if low_candidates:
                print(f"   low í›„ë³´ í•„ë“œ: {low_candidates}")
            print(f"   ìƒ˜í”Œ ì‘ë‹µ: {str(sample_row)[:500]}")
        
        df = pd.DataFrame(
            [
                {
                    "date": r.get("dt") or r.get("date") or r.get("stck_bsop_date"),
                    # ka10081 API ì‹¤ì œ ì‘ë‹µ í•„ë“œëª…: open_pric, high_pric, low_pric, cur_prc, trde_qty
                    "open": float(r.get("open_pric") or r.get("opn_prc") or r.get("open_prc") or r.get("open") or r.get("stck_oprc") or 0),
                    "high": float(r.get("high_pric") or r.get("stck_hgpr") or r.get("high_prc") or r.get("hg_prc") or r.get("high") or 0),
                    "low": float(r.get("low_pric") or r.get("stck_lwpr") or r.get("low_prc") or r.get("lw_prc") or r.get("low") or 0),
                    # ì¢…ê°€ ìš°ì„ . ì¥ì¤‘ì—ëŠ” cls_prcê°€ ë¹„ê±°ë‚˜ 0ì¼ ìˆ˜ ìˆì–´ cur_prcë¥¼ ë³´ì¡°ë¡œ ì‚¬ìš©
                    "close": float(r.get("cur_prc") or r.get("stck_clpr") or r.get("cls_prc") or r.get("close") or 0),
                    "volume": int(r.get("trde_qty") or r.get("acml_vol") or r.get("trd_qty") or r.get("volume") or 0),
                }
                for r in rows
            ]
        )
        if df.empty:
            return df
        # ìœ íš¨ ë°ì´í„°ë§Œ í•„í„°(ì¢…ê°€/ê±°ë˜ëŸ‰ 0 ì œê±°)
        df = df[(df["close"] > 0) & (df["volume"] > 0)]
        if df.empty:
            return df
        # ë‚ ì§œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ ë° tail(count)
        df = df.sort_values("date").reset_index(drop=True).tail(count)
        return df

    def _gen_mock_ohlcv(self, code: str, count: int, base_dt: str = None) -> pd.DataFrame:
        seed = int(code[-4:], 10) if code.isdigit() else 42
        rng = np.random.default_rng(seed)
        
        # base_dtê°€ ì§€ì •ë˜ë©´ í•´ë‹¹ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒì„±
        if base_dt:
            try:
                end_date = pd.to_datetime(base_dt, format='%Y%m%d').normalize()
            except:
                end_date = pd.Timestamp.today().normalize()
        else:
            end_date = pd.Timestamp.today().normalize()
            
        dates = pd.date_range(end=end_date, periods=count, freq="B")
        prices = np.cumsum(rng.normal(loc=0.2, scale=1.5, size=len(dates))) + 50000
        prices = np.clip(prices, a_min=1000, a_max=None)
        close = pd.Series(prices).astype(float)
        # ìµœê·¼ 30ì˜ì—…ì¼ì— ìƒìŠ¹ ì¶”ì„¸ ë° ë§ˆì§€ë§‰ ë‚  ì¶”ê°€ ë ë¦¬ ë¶€ì—¬ (ê³¨ë“ í¬ë¡œìŠ¤/ëª¨ë©˜í…€ ìœ ë„)
        tail_len = min(30, len(close))
        close.iloc[-tail_len:] = close.iloc[-tail_len:] + np.linspace(0, 1500, tail_len)
        close.iloc[-1] = close.iloc[-2] + max(200.0, abs(rng.normal(250.0, 80.0)))
        close = close.round(0)
        # ê³ ì €/ì‹œê°€/ê±°ë˜ëŸ‰ ìƒì„±
        high = (close + rng.normal(50, 100, size=len(dates))).clip(lower=close)
        low = (close - rng.normal(50, 100, size=len(dates))).clip(lower=1000)
        open_ = close.shift(1).fillna(close.iloc[0])
        volume = rng.integers(100000, 5000000, size=len(dates)).astype(float)
        # ìµœê·¼ 5ì¼ì€ ì ì¦, ë§ˆì§€ë§‰ ë‚ ì€ ê°•í•œ ìŠ¤íŒŒì´í¬ (ê±°ë˜í™•ëŒ€ ì¡°ê±´ ìœ ë„)
        vol_tail = min(5, len(volume))
        for i in range(1, vol_tail + 1):
            volume[-i] *= 1.0 + (i - 1) * 0.2
        volume[-1] *= 3.0
        df = pd.DataFrame({
            "date": dates.strftime("%Y%m%d"),
            "open": open_.astype(float),
            "high": high.astype(float),
            "low": low.astype(float),
            "close": close.astype(float),
            "volume": volume.astype(int),
        })
        return df.reset_index(drop=True)

    def get_stock_quote(self, code: str) -> dict:
        """ì¢…ëª©ì˜ í˜„ì¬ê°€ ì •ë³´ ì¡°íšŒ (í‚¤ì›€ REST API ë°˜í™˜ê°’ ì‚¬ìš©)"""
        if self.force_mock:
            return {
                "current_price": 50000.0,
                "change_rate": 2.5,
                "volume": 1000000,
                "market_cap": 1000000000000
            }
        
        try:
            # í˜„ì¬ê°€ ì¡°íšŒ API í˜¸ì¶œ (ka10001 ë“±)
            api_id = config.kiwoom_tr_quote_id if hasattr(config, 'kiwoom_tr_quote_id') else "ka10001"
            path = config.kiwoom_tr_quote_path if hasattr(config, 'kiwoom_tr_quote_path') else "/api/dostk/krinfo"
            
            payload = {
                "FID_COND_MRKT_DIV_CODE": "J",
                "FID_INPUT_ISCD": code
            }
            data = self._post(api_id, path, payload)
            
            # API ì‘ë‹µì—ì„œ í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ
            output = data.get("output") or {}
            
            current_price = float(output.get("stck_prpr") or 0)
            change_rate = round(float(output.get("prdy_ctrt") or 0), 2)
            volume = int(output.get("acml_vol") or 0)
            market_cap = int(output.get("hts_avls") or 0)
            
            return {
                "current_price": current_price,
                "change_rate": change_rate,
                "volume": volume,
                "market_cap": market_cap
            }
                
        except Exception as e:
            print(f"âš ï¸ {code} ì¢…ëª© ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            # API ì‹¤íŒ¨ ì‹œ OHLCV ë°ì´í„°ë¡œ í´ë°± (ë“±ë½ë¥  ê³„ì‚° ì—†ì´)
            try:
                df = self.get_ohlcv(code, 1)
                if not df.empty:
                    latest = df.iloc[-1]
                    return {
                        "current_price": float(latest["close"]),
                        "change_rate": 0.0,  # ë“±ë½ë¥ ì€ ê³„ì‚°í•˜ì§€ ì•ŠìŒ
                        "volume": int(latest["volume"]),
                        "market_cap": 0
                    }
            except:
                pass
            return {"error": str(e)}

    def get_overseas_ohlcv(self, symbol: str, count: int = 220, base_dt: str = None) -> pd.DataFrame:
        """í•´ì™¸ì£¼ì‹ ì¼ë´‰ OHLCV ì¡°íšŒ (ë¯¸êµ­ ì£¼ì‹/ETF/ì§€ìˆ˜)"""
        if self.force_mock:
            return self._gen_mock_overseas_ohlcv(symbol, count, base_dt)
        
        try:
            # í•´ì™¸ì£¼ì‹ ì¼ë´‰ ì¡°íšŒ API (ì˜ˆ: ka10082)
            api_id = getattr(config, 'kiwoom_tr_overseas_ohlcv_id', 'ka10082')
            path = getattr(config, 'kiwoom_tr_overseas_ohlcv_path', '/api/dostk/overseas')
            
            # ë¯¸êµ­ ì£¼ì‹ ì‹¬ë³¼ ë§¤í•‘
            symbol_map = {
                'SPY': 'SPY',
                'QQQ': 'QQQ', 
                '^VIX': 'VIX',
                'VIX': 'VIX',
                '^TNX': 'TNX',
                'TNX': 'TNX',
                'ES=F': 'ES',
                'NQ=F': 'NQ',
                'VX=F': 'VX',
                'KRW=X': 'USDKRW'
            }
            
            overseas_symbol = symbol_map.get(symbol, symbol)
            
            payload = {
                'symbol': overseas_symbol,
                'market': 'US',  # ë¯¸êµ­ ì‹œì¥
                'period': 'D',   # ì¼ë´‰
                'count': str(count)
            }
            
            if base_dt:
                payload['end_date'] = base_dt
            
            data = self._post(api_id, path, payload)
            
            # ì‘ë‹µ ë°ì´í„° íŒŒì‹±
            rows = data.get('output', []) or data.get('data', []) or data.get('list', [])
            
            if not rows:
                return pd.DataFrame()
            
            df_data = []
            for row in rows:
                df_data.append({
                    'date': row.get('date') or row.get('dt') or row.get('trade_date'),
                    'open': float(row.get('open') or row.get('open_price') or 0),
                    'high': float(row.get('high') or row.get('high_price') or 0),
                    'low': float(row.get('low') or row.get('low_price') or 0),
                    'close': float(row.get('close') or row.get('close_price') or 0),
                    'volume': int(row.get('volume') or row.get('trade_volume') or 0)
                })
            
            df = pd.DataFrame(df_data)
            
            if df.empty:
                return df
            
            # ìœ íš¨ ë°ì´í„° í•„í„°ë§
            df = df[(df['close'] > 0) & (df['volume'] > 0)]
            
            # ë‚ ì§œ ì •ë ¬
            df = df.sort_values('date').reset_index(drop=True).tail(count)
            
            return df
            
        except Exception as e:
            # API ì‹¤íŒ¨ ì‹œ ëª¨ì˜ ë°ì´í„°ë¡œ fallback
            return self._gen_mock_overseas_ohlcv(symbol, count, base_dt)
    
    def _gen_mock_overseas_ohlcv(self, symbol: str, count: int, base_dt: str = None) -> pd.DataFrame:
        """í•´ì™¸ì£¼ì‹ ëª¨ì˜ ë°ì´í„° ìƒì„±"""
        import numpy as np
        
        # ì‹œë“œ ì„¤ì •
        seed = hash(symbol) % 1000
        np.random.seed(seed)
        
        # ê¸°ì¤€ ë‚ ì§œ ì„¤ì •
        if base_dt:
            try:
                end_date = pd.to_datetime(base_dt, format='%Y%m%d').normalize()
            except:
                end_date = pd.Timestamp.today().normalize()
        else:
            end_date = pd.Timestamp.today().normalize()
        
        # ì˜ì—…ì¼ ê¸°ì¤€ ë‚ ì§œ ìƒì„±
        dates = pd.bdate_range(end=end_date, periods=count)
        
        # ì‹¬ë³¼ë³„ ê¸°ë³¸ ê°€ê²© ë° íŠ¹ì„±
        symbol_config = {
            'SPY': {'base_price': 450.0, 'volatility': 0.015, 'trend': 0.0005},
            'QQQ': {'base_price': 380.0, 'volatility': 0.020, 'trend': 0.0008},
            '^VIX': {'base_price': 20.0, 'volatility': 0.05, 'trend': -0.001, 'mean_revert': True},
            'VIX': {'base_price': 20.0, 'volatility': 0.05, 'trend': -0.001, 'mean_revert': True},
            '^TNX': {'base_price': 4.5, 'volatility': 0.02, 'trend': 0.0002},
            'TNX': {'base_price': 4.5, 'volatility': 0.02, 'trend': 0.0002},
            'ES=F': {'base_price': 4500.0, 'volatility': 0.018, 'trend': 0.0005},
            'NQ=F': {'base_price': 15000.0, 'volatility': 0.022, 'trend': 0.0008},
            'VX=F': {'base_price': 20.0, 'volatility': 0.05, 'trend': -0.001, 'mean_revert': True},
            'KRW=X': {'base_price': 1300.0, 'volatility': 0.008, 'trend': 0.0001}
        }
        
        config = symbol_config.get(symbol, {'base_price': 100.0, 'volatility': 0.015, 'trend': 0.0})
        
        # ê°€ê²© ì‹œê³„ì—´ ìƒì„±
        returns = np.random.normal(config['trend'], config['volatility'], len(dates))
        
        # VIX ê³„ì—´ì€ í‰ê·  íšŒê·€ íŠ¹ì„± ì ìš©
        if config.get('mean_revert'):
            for i in range(1, len(returns)):
                current_price = config['base_price'] * np.exp(returns[:i].sum())
                if current_price > 35:  # VIX 35 ì´ìƒì—ì„œ í•˜ë½ ì••ë ¥
                    returns[i] = -abs(returns[i])
                elif current_price < 12:  # VIX 12 ì´í•˜ì—ì„œ ìƒìŠ¹ ì••ë ¥
                    returns[i] = abs(returns[i])
        
        # ëˆ„ì  ìˆ˜ìµë¥ ë¡œ ê°€ê²© ê³„ì‚°
        prices = config['base_price'] * np.exp(np.cumsum(returns))
        
        # OHLCV ë°ì´í„° ìƒì„±
        data = []
        for i, (date, close) in enumerate(zip(dates, prices)):
            daily_vol = np.random.uniform(0.005, 0.02)
            high = close * (1 + daily_vol)
            low = close * (1 - daily_vol)
            open_price = close * (1 + np.random.uniform(-0.01, 0.01))
            
            # ê±°ë˜ëŸ‰ (ì‹¬ë³¼ë³„ ì°¨ë“±)
            if 'VIX' in symbol or 'VX' in symbol:
                volume = int(np.random.uniform(50000, 500000))  # VIXëŠ” ê±°ë˜ëŸ‰ ì ìŒ
            elif symbol in ['SPY', 'QQQ']:
                volume = int(np.random.uniform(10000000, 100000000))  # ETFëŠ” ê±°ë˜ëŸ‰ ë§ìŒ
            else:
                volume = int(np.random.uniform(1000000, 10000000))
            
            data.append({
                'date': date.strftime('%Y%m%d'),
                'open': round(open_price, 2),
                'high': round(high, 2),
                'low': round(low, 2),
                'close': round(close, 2),
                'volume': volume
            })
        
        df = pd.DataFrame(data)
        df['date'] = pd.to_datetime(df['date'], format='%Y%m%d')
        
        return df

    def get_stock_name(self, code: str) -> str:
        """ì½”ë“œâ†’ì´ë¦„ ë§¤í•‘ (ìºì‹œ ìš°ì„ ). ì‹¤íŒ¨ ì‹œ ì½”ë“œ ê·¸ëŒ€ë¡œ ë°˜í™˜"""
        if code in self._code_to_name:
            return self._code_to_name[code]
        if self.force_mock:
            name = self._mock_names.get(code, code)
            self._code_to_name[code] = name
            self._name_to_code[name.replace(" ", "")] = code
            return name
        # ìºì‹œ ë¯¸ìŠ¤ ì‹œ ì‹¬ë³¼ í”„ë¦¬ë¡œë“œ ì¬ì‹œë„
        try:
            self._preload_symbols()
        except Exception:
            pass
        name = self._code_to_name.get(code, code)
        if name != code:
            self._name_to_code[name.replace(" ", "")] = code
        return name

    def get_code_by_name(self, name: str) -> str:
        """ì´ë¦„â†’ì½”ë“œ ë§¤í•‘. 1) ìºì‹œ 2) (ëª¨ì˜/ì‹¤ì œ) ì¡°íšŒ 3) ìœ ë‹ˆë²„ìŠ¤ í›„ ì—­ë§¤í•‘"""
        key = name.replace(" ", "")
        # ë¸Œëœë“œ ì•½ì–´/ë°œìŒ í‘œì¤€í™”
        norm_map = {
            "sk": "ì—ìŠ¤ì¼€ì´",
            "lg": "ì—˜ì§€",
            "kt": "ì¼€ì´í‹°",
            "cj": "ì”¨ì œì´",
            "posco": "í¬ìŠ¤ì½”",
        }
        low = key.lower()
        for abbr, full in norm_map.items():
            if low.startswith(abbr):
                key = key.replace(key[:len(abbr)], full)
                break
        # ìì£¼ ì“°ëŠ” ë³„ì¹­
        alias = {
            "skì´ë…¸ë² ì´ì…˜": "096770",
            "ì—ìŠ¤ì¼€ì´ì´ë…¸ë² ì´ì…˜": "096770",
        }
        if key in alias:
            return alias[key]
        if key in self._name_to_code:
            return self._name_to_code[key]

        if self.force_mock:
            # ë¶€ë¶„ ì¼ì¹˜ í—ˆìš©
            for code, nm in self._mock_names.items():
                if key in nm.replace(" ", ""):
                    self._name_to_code[key] = code
                    self._code_to_name[code] = nm
                    return code
            return ""

        # 1) ìºì‹œ ë‚´ ë¶€ë¶„ ì¼ì¹˜ ê²€ìƒ‰
        for cd, nm in self._code_to_name.items():
            if key in nm.replace(" ", ""):
                self._name_to_code[key] = cd
                return cd
        # 2) ìºì‹œê°€ ë¹„ì–´ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ í”„ë¦¬ë¡œë“œ ì¬ì‹œë„ í›„ ë‹¤ì‹œ ê²€ìƒ‰
        try:
            self._preload_symbols()
            for cd, nm in self._code_to_name.items():
                if key in nm.replace(" ", ""):
                    self._name_to_code[key] = cd
                    return cd
        except Exception:
            pass

        # 2) ìœ ë‹ˆë²„ìŠ¤ ìƒìœ„ ì½”ë“œ ì¡°íšŒ í›„ ì´ë¦„ ì—­ë§¤í•‘ (ë³´ìˆ˜ì )
        codes = []
        try:
            codes += self.get_top_codes("KOSPI", min(200, config.universe_kospi))
            codes += self.get_top_codes("KOSDAQ", min(200, config.universe_kosdaq))
        except Exception:
            codes = []
        for cd in codes:
            nm = self.get_stock_name(cd)
            if name.replace(" ", "") in nm.replace(" ", ""):
                self._name_to_code[name.replace(" ", "")] = cd
                return cd
        # ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¬¸ìì—´
        return ""


# ì „ì—­ API ì¸ìŠ¤í„´ìŠ¤
api = KiwoomAPI()


