import schedule
import time
import requests
import logging
from datetime import datetime, timedelta
import holidays
import os
import pytz
from environment import get_environment_info
from db_manager import db_manager

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def get_notification_recipients():
    """ì•Œë¦¼ ìˆ˜ì‹ ì ëª©ë¡ì„ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ"""
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì•Œë¦¼ ìˆ˜ì‹  ë™ì˜í•œ ì‚¬ìš©ì ì¡°íšŒ
        with db_manager.get_cursor(commit=False) as cursor:
            cursor.execute("""
                SELECT phone
                FROM users
                WHERE notification_enabled = TRUE
                  AND phone IS NOT NULL
                  AND phone != ''
            """)
            rows = cursor.fetchall()
        
        recipients = [row["phone"] for row in rows if row.get("phone")]
        
        if recipients:
            logger.info(f"ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ {len(recipients)}ëª…ì˜ ìˆ˜ì‹ ì ì¡°íšŒ")
            return recipients
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ìˆ˜ì‹ ìê°€ ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ê¸° (fallback)
        env_recipients = os.getenv('NOTIFICATION_RECIPIENTS', '').split(',')
        fallback_recipients = [r.strip() for r in env_recipients if r.strip()]
        
        if fallback_recipients:
            logger.info(f"í™˜ê²½ë³€ìˆ˜ì—ì„œ {len(fallback_recipients)}ëª…ì˜ ìˆ˜ì‹ ì ì¡°íšŒ")
        
        return fallback_recipients
        
    except Exception as e:
        logger.error(f"ìˆ˜ì‹ ì ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        # ì—ëŸ¬ ì‹œ í™˜ê²½ë³€ìˆ˜ fallback
        env_recipients = os.getenv('NOTIFICATION_RECIPIENTS', '').split(',')
        return [r.strip() for r in env_recipients if r.strip()]

def is_trading_day():
    """ê±°ë˜ì¼ì¸ì§€ í™•ì¸ (ì£¼ë§ê³¼ ê³µíœ´ì¼ ì œì™¸) - KST ê¸°ì¤€"""
    # KST ì‹œê°„ëŒ€ ì‚¬ìš©
    kst = pytz.timezone('Asia/Seoul')
    today = datetime.now(kst).date()
    
    # ì£¼ë§ ì²´í¬
    if today.weekday() >= 5:  # í† ìš”ì¼(5), ì¼ìš”ì¼(6)
        return False
    
    # í•œêµ­ ê³µíœ´ì¼ ì²´í¬
    kr_holidays = holidays.SouthKorea()
    if today in kr_holidays:
        return False
    
    return True

def is_us_trading_day():
    """ë¯¸êµ­ ê±°ë˜ì¼ì¸ì§€ í™•ì¸ (ì£¼ë§ê³¼ ë¯¸êµ­ ê³µíœ´ì¼ ì œì™¸) - KST ê¸°ì¤€"""
    # KST ì‹œê°„ëŒ€ ì‚¬ìš©
    kst = pytz.timezone('Asia/Seoul')
    now_kst = datetime.now(kst)
    
    # ë¯¸êµ­ ì‹œê°„ëŒ€ë¡œ ë³€í™˜ (EST/EDT)
    # ì„œë¨¸íƒ€ì„ ìë™ ì²˜ë¦¬
    us_eastern = pytz.timezone('US/Eastern')
    now_us = now_kst.astimezone(us_eastern)
    today_us = now_us.date()
    
    # ì£¼ë§ ì²´í¬ (í† ìš”ì¼, ì¼ìš”ì¼)
    if today_us.weekday() >= 5:
        return False
    
    # ë¯¸êµ­ ê³µíœ´ì¼ ì²´í¬
    try:
        us_holidays = holidays.UnitedStates()
        if today_us in us_holidays:
            return False
    except Exception:
        # holidays ëª¨ë“ˆì—ì„œ ë¯¸êµ­ ê³µíœ´ì¼ì„ ì§€ì›í•˜ì§€ ì•Šìœ¼ë©´ ì£¼ë§ë§Œ ì²´í¬
        pass
    
    return True

def run_market_analysis():
    """ì¥ì„¸ ë¶„ì„ ì‹¤í–‰ (15:35)"""
    if not is_trading_day():
        logger.info(f"ì˜¤ëŠ˜ì€ ê±°ë˜ì¼ì´ ì•„ë‹™ë‹ˆë‹¤. ì¥ì„¸ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    try:
        logger.info("ğŸ“Š ìë™ ì¥ì„¸ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        from market_analyzer import market_analyzer
        from datetime import datetime
        from db_manager import db_manager
        import json
        
        # ì˜¤ëŠ˜ ë‚ ì§œ (YYYYMMDD í˜•ì‹)
        today = datetime.now().strftime('%Y%m%d')
        
        # ë ˆì§ ë²„ì „ ê°€ì ¸ì˜¤ê¸°
        try:
            from config import config
            regime_version = getattr(config, 'regime_version', 'v1')
        except Exception:
            regime_version = 'v1'
        
        # ì¥ì„¸ ë¶„ì„ ì‹¤í–‰ (ë ˆì§ ë²„ì „ ìë™ ì„ íƒ)
        market_condition = market_analyzer.analyze_market_condition(today, regime_version=regime_version)
        
        # ë ˆì§ ë²„ì „ì— ë”°ë¥¸ ë¡œê·¸ ì¶œë ¥
        if hasattr(market_condition, 'version'):
            if market_condition.version == 'regime_v4':
                logger.info(f"ğŸ“Š Global Regime v4 ë¶„ì„ ì™„ë£Œ: {market_condition.final_regime} (trend: {market_condition.global_trend_score:.2f}, risk: {market_condition.global_risk_score:.2f})")
            elif market_condition.version == 'regime_v3':
                logger.info(f"ğŸ“Š Global Regime v3 ë¶„ì„ ì™„ë£Œ: {market_condition.final_regime} (ì ìˆ˜: {market_condition.final_score:.2f})")
            else:
                logger.info(f"ğŸ“Š ì¥ì„¸ ë¶„ì„ v1 ì™„ë£Œ: {market_condition.market_sentiment} (ìœ íš¨ ìˆ˜ìµë¥ : {market_condition.kospi_return*100:.2f}%, RSI ì„ê³„ê°’: {market_condition.rsi_threshold})")
        else:
            logger.info(f"ğŸ“Š ì¥ì„¸ ë¶„ì„ ì™„ë£Œ: {market_condition.market_sentiment} (ìœ íš¨ ìˆ˜ìµë¥ : {market_condition.kospi_return*100:.2f}%, RSI ì„ê³„ê°’: {market_condition.rsi_threshold})")
        
        # DBì— ì €ì¥
        with db_manager.get_cursor(commit=True) as cur:
            cur.execute("""
                INSERT INTO market_conditions(
                    date, market_sentiment, sentiment_score, kospi_return, volatility, rsi_threshold,
                    sector_rotation, foreign_flow, institution_flow, volume_trend,
                    min_signals, macd_osc_min, vol_ma5_mult, gap_max, ext_from_tema20_max,
                    trend_metrics, breadth_metrics, flow_metrics, sector_metrics, volatility_metrics,
                    foreign_flow_label, institution_flow_label, volume_trend_label, adjusted_params, analysis_notes
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (date) DO UPDATE SET
                    market_sentiment = EXCLUDED.market_sentiment,
                    sentiment_score = EXCLUDED.sentiment_score,
                    kospi_return = EXCLUDED.kospi_return,
                    volatility = EXCLUDED.volatility,
                    rsi_threshold = EXCLUDED.rsi_threshold,
                    sector_rotation = EXCLUDED.sector_rotation,
                    foreign_flow = EXCLUDED.foreign_flow,
                    institution_flow = EXCLUDED.institution_flow,
                    volume_trend = EXCLUDED.volume_trend,
                    min_signals = EXCLUDED.min_signals,
                    macd_osc_min = EXCLUDED.macd_osc_min,
                    vol_ma5_mult = EXCLUDED.vol_ma5_mult,
                    gap_max = EXCLUDED.gap_max,
                    ext_from_tema20_max = EXCLUDED.ext_from_tema20_max,
                    trend_metrics = EXCLUDED.trend_metrics,
                    breadth_metrics = EXCLUDED.breadth_metrics,
                    flow_metrics = EXCLUDED.flow_metrics,
                    sector_metrics = EXCLUDED.sector_metrics,
                    volatility_metrics = EXCLUDED.volatility_metrics,
                    foreign_flow_label = EXCLUDED.foreign_flow_label,
                    institution_flow_label = EXCLUDED.institution_flow_label,
                    volume_trend_label = EXCLUDED.volume_trend_label,
                    adjusted_params = EXCLUDED.adjusted_params,
                    analysis_notes = EXCLUDED.analysis_notes,
                    updated_at = NOW()
            """, (
                today,
                market_condition.market_sentiment,
                market_condition.sentiment_score,
                market_condition.kospi_return,
                market_condition.volatility,
                market_condition.rsi_threshold,
                market_condition.sector_rotation,
                market_condition.foreign_flow,
                market_condition.institution_flow,
                market_condition.volume_trend,
                market_condition.min_signals,
                market_condition.macd_osc_min,
                market_condition.vol_ma5_mult,
                market_condition.gap_max,
                market_condition.ext_from_tema20_max,
                json.dumps(market_condition.trend_metrics) if market_condition.trend_metrics else None,
                json.dumps(market_condition.breadth_metrics) if market_condition.breadth_metrics else None,
                json.dumps(market_condition.flow_metrics) if market_condition.flow_metrics else None,
                json.dumps(market_condition.sector_metrics) if market_condition.sector_metrics else None,
                json.dumps(market_condition.volatility_metrics) if market_condition.volatility_metrics else None,
                market_condition.foreign_flow_label,
                market_condition.institution_flow_label,
                market_condition.volume_trend_label,
                json.dumps(market_condition.adjusted_params) if market_condition.adjusted_params else None,
                market_condition.analysis_notes
            ))
        
        logger.info(f"âœ… ì¥ì„¸ ë¶„ì„ ê²°ê³¼ê°€ DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {today}")
        
    except Exception as e:
        logger.error(f"ìë™ ì¥ì„¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())

def run_scan():
    """í•œêµ­ ì£¼ì‹ ìŠ¤ìº” ì‹¤í–‰ (15:42)"""
    if not is_trading_day():
        logger.info(f"ì˜¤ëŠ˜ì€ ê±°ë˜ì¼ì´ ì•„ë‹™ë‹ˆë‹¤. ìŠ¤ìº”ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    try:
        logger.info("ğŸ“ˆ í•œêµ­ ì£¼ì‹ ìë™ ìŠ¤ìº”ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # ë°±ì—”ë“œ API í˜¸ì¶œ (í™˜ê²½ë³„ URL ì‚¬ìš©)
        env_info = get_environment_info()
        if env_info['is_local']:
            backend_url = "http://localhost:8010"
        else:
            backend_url = "http://localhost:8010"  # ì„œë²„ì—ì„œëŠ” ë‚´ë¶€ í†µì‹ 
        
        response = requests.get(f"{backend_url}/scan?save_snapshot=true", timeout=300)
        
        if response.status_code == 200:
            data = response.json()
            matched_count = data.get('matched_count', 0)
            logger.info(f"âœ… í•œêµ­ ì£¼ì‹ ìë™ ìŠ¤ìº” ì™„ë£Œ: {matched_count}ê°œ ì¢…ëª© ë§¤ì¹­")
            
            # ìŠ¤ìº” ê²°ê³¼ëŠ” DBì— ì €ì¥ë¨ (JSON íŒŒì¼ ì €ì¥ ì œê±°)
            logger.info("ìŠ¤ìº” ê²°ê³¼ê°€ DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ìë™ ì•Œë¦¼ ë°œì†¡
            send_auto_notification(matched_count)
            
        else:
            logger.error(f"í•œêµ­ ì£¼ì‹ ìŠ¤ìº” ì‹¤íŒ¨: HTTP {response.status_code}")
            
    except Exception as e:
        logger.error(f"í•œêµ­ ì£¼ì‹ ìë™ ìŠ¤ìº” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def run_us_scan():
    """ë¯¸êµ­ ì£¼ì‹ ìŠ¤ìº” ì‹¤í–‰ (ì˜¤ì „ 7:00 KST)"""
    # ë¯¸êµ­ ì‹œì¥ì´ ë§ˆê°ëœ í›„ ë°ì´í„° í™•ì • ì‹œì ì— ì‹¤í–‰
    # ì„œë¨¸íƒ€ì„: ë¯¸êµ­ ì •ê·œì¥ ë§ˆê° 5:00 KST â†’ ìŠ¤ìº” 7:00 KST
    # ë¹„ì„œë¨¸íƒ€ì„: ë¯¸êµ­ ì •ê·œì¥ ë§ˆê° 6:00 KST â†’ ìŠ¤ìº” 7:00 KST
    if not is_us_trading_day():
        logger.info(f"ì˜¤ëŠ˜ì€ ë¯¸êµ­ ê±°ë˜ì¼ì´ ì•„ë‹™ë‹ˆë‹¤. ë¯¸êµ­ ì£¼ì‹ ìŠ¤ìº”ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    try:
        logger.info("ğŸ‡ºğŸ‡¸ ë¯¸êµ­ ì£¼ì‹ ìë™ ìŠ¤ìº”ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # ë°±ì—”ë“œ API í˜¸ì¶œ (í™˜ê²½ë³„ URL ì‚¬ìš©)
        env_info = get_environment_info()
        if env_info['is_local']:
            backend_url = "http://localhost:8010"
        else:
            backend_url = "http://localhost:8010"  # ì„œë²„ì—ì„œëŠ” ë‚´ë¶€ í†µì‹ 
        
        # S&P 500 + NASDAQ 100 í†µí•© ìŠ¤ìº”
        response = requests.get(
            f"{backend_url}/scan/us-stocks?universe_type=combined&limit=500&save_snapshot=true",
            timeout=600  # ë¯¸êµ­ ì£¼ì‹ì€ ì¢…ëª© ìˆ˜ê°€ ë§ì•„ íƒ€ì„ì•„ì›ƒì„ ë” ê¸¸ê²Œ
        )
        
        if response.status_code == 200:
            data = response.json()
            matched_count = data.get('matched_count', 0)
            logger.info(f"âœ… ë¯¸êµ­ ì£¼ì‹ ìë™ ìŠ¤ìº” ì™„ë£Œ: {matched_count}ê°œ ì¢…ëª© ë§¤ì¹­")
            
            # ìŠ¤ìº” ê²°ê³¼ëŠ” DBì— ì €ì¥ë¨
            logger.info("ë¯¸êµ­ ì£¼ì‹ ìŠ¤ìº” ê²°ê³¼ê°€ DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        else:
            logger.error(f"ë¯¸êµ­ ì£¼ì‹ ìŠ¤ìº” ì‹¤íŒ¨: HTTP {response.status_code}")
            
    except Exception as e:
        logger.error(f"ë¯¸êµ­ ì£¼ì‹ ìë™ ìŠ¤ìº” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())

def send_auto_notification(matched_count):
    """ìë™ ì•Œë¦¼ ë°œì†¡ (ì†”ë¼í”¼ ì•Œë¦¼í†¡)"""
    try:
        # ì•Œë¦¼ ìˆ˜ì‹ ì ëª©ë¡ (íŒŒì¼ì—ì„œ ì‹¤ì‹œê°„ ì½ê¸°)
        notification_recipients = get_notification_recipients()
        
        if not notification_recipients:
            logger.info("ì•Œë¦¼ ìˆ˜ì‹ ìê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # ì†”ë¼í”¼ ì•Œë¦¼í†¡ í…œí”Œë¦¿ ë³€ìˆ˜ ìƒì„±
        from kakao import format_scan_alert_message, send_alert
        
        scan_date = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
        template_data = format_scan_alert_message(
            matched_count=matched_count,
            scan_date=scan_date,
            user_name="ê³ ê°ë‹˜"
        )
        
        # ê° ìˆ˜ì‹ ìì—ê²Œ ì•Œë¦¼ ë°œì†¡
        for recipient in notification_recipients:
            try:
                # ì†”ë¼í”¼ ì•Œë¦¼í†¡ ë°œì†¡
                result = send_alert(to=recipient, template_data=template_data)
                
                if result.get('ok'):
                    logger.info(f"ì†”ë¼í”¼ ì•Œë¦¼í†¡ ë°œì†¡ ì„±ê³µ: {recipient}")
                else:
                    logger.error(f"ì†”ë¼í”¼ ì•Œë¦¼í†¡ ë°œì†¡ ì‹¤íŒ¨: {recipient}, {result.get('error', 'Unknown error')}")
                    
            except Exception as e:
                logger.error(f"ì•Œë¦¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜ ({recipient}): {str(e)}")
                
    except Exception as e:
        logger.error(f"ìë™ ì•Œë¦¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def preload_regime_cache_kr():
    """í•œêµ­ ì£¼ì‹ ë ˆì§ ë¶„ì„ìš© ìºì‹œ ì‚¬ì „ ìƒì„± (15:35)"""
    if not is_trading_day():
        logger.info("ì˜¤ëŠ˜ì€ ê±°ë˜ì¼ì´ ì•„ë‹™ë‹ˆë‹¤. ë ˆì§ ë¶„ì„ìš© ìºì‹œ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    try:
        logger.info("ğŸ“Š ë ˆì§ ë¶„ì„ìš© ìºì‹œ ì‚¬ì „ ìƒì„± ì‹œì‘ (í•œêµ­)")
        
        # 1. KOSPI ë°ì´í„° (FinanceDataReader ìë™ ìƒì„±)
        try:
            import FinanceDataReader as fdr
            today = datetime.now().strftime('%Y-%m-%d')
            start_date = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')
            kospi_df = fdr.DataReader('KS11', start_date, today)
            if not kospi_df.empty:
                logger.info(f"âœ… KOSPI ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(kospi_df)}ê°œ í–‰")
            else:
                logger.warning("KOSPI ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        except ImportError:
            logger.warning("FinanceDataReaderê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
        except Exception as e:
            logger.warning(f"KOSPI ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
        
        # 2. KOSDAQ ë°ì´í„° (CSV ìºì‹œ í™•ì¸/ìƒì„±)
        kosdaq_csv = os.path.join(os.path.dirname(__file__), '..', 'data_cache', 'ohlcv', '229200.csv')
        if os.path.exists(kosdaq_csv):
            logger.info("âœ… KOSDAQ ìºì‹œ í™•ì¸ë¨")
        else:
            logger.warning("KOSDAQ ìºì‹œ ì—†ìŒ - ìˆ˜ë™ ìƒì„± í•„ìš”")
        
        # 3. ë¯¸êµ­ ì„ ë¬¼ ë°ì´í„° (ë ˆì§ ë¶„ì„ì— í•„ìš”)
        try:
            from services.us_futures_data_v8 import us_futures_data_v8
            symbols = ['SPY', 'QQQ', '^VIX']
            for symbol in symbols:
                try:
                    df = us_futures_data_v8.fetch_data(symbol, period='1y')
                    if not df.empty:
                        logger.info(f"âœ… {symbol} ìºì‹œ ìƒì„± ì™„ë£Œ: {len(df)}ê°œ í–‰")
                    else:
                        logger.warning(f"{symbol} ìºì‹œ ìƒì„± ì‹¤íŒ¨ (ë¹ˆ ë°ì´í„°)")
                except Exception as e:
                    logger.error(f"{symbol} ìºì‹œ ìƒì„± ì˜¤ë¥˜: {e}")
        except Exception as e:
            logger.error(f"ë¯¸êµ­ ì„ ë¬¼ ë°ì´í„° ìºì‹œ ìƒì„± ì‹¤íŒ¨: {e}")
        
        logger.info("âœ… ë ˆì§ ë¶„ì„ìš© ìºì‹œ ì‚¬ì „ ìƒì„± ì™„ë£Œ (í•œêµ­)")
        
    except Exception as e:
        logger.error(f"ë ˆì§ ë¶„ì„ìš© ìºì‹œ ì‚¬ì „ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())

def preload_regime_cache_us():
    """ë¯¸êµ­ ì£¼ì‹ ë ˆì§ ë¶„ì„ìš© ìºì‹œ ì‚¬ì „ ìƒì„± (06:50)"""
    if not is_us_trading_day():
        logger.info("ì˜¤ëŠ˜ì€ ë¯¸êµ­ ê±°ë˜ì¼ì´ ì•„ë‹™ë‹ˆë‹¤. ë ˆì§ ë¶„ì„ìš© ìºì‹œ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    try:
        logger.info("ğŸ“Š ë ˆì§ ë¶„ì„ìš© ìºì‹œ ì‚¬ì „ ìƒì„± ì‹œì‘ (ë¯¸êµ­)")
        
        from services.us_futures_data_v8 import us_futures_data_v8
        symbols = ['SPY', 'QQQ', '^VIX', 'ES=F', 'NQ=F', 'DX-Y.NYB']
        
        for symbol in symbols:
            try:
                df = us_futures_data_v8.fetch_data(symbol, period='1y')
                if not df.empty:
                    logger.info(f"âœ… {symbol} ìºì‹œ ìƒì„± ì™„ë£Œ: {len(df)}ê°œ í–‰")
                else:
                    logger.warning(f"{symbol} ìºì‹œ ìƒì„± ì‹¤íŒ¨ (ë¹ˆ ë°ì´í„°)")
            except Exception as e:
                logger.error(f"{symbol} ìºì‹œ ìƒì„± ì˜¤ë¥˜: {e}")
        
        logger.info("âœ… ë ˆì§ ë¶„ì„ìš© ìºì‹œ ì‚¬ì „ ìƒì„± ì™„ë£Œ (ë¯¸êµ­)")
        
    except Exception as e:
        logger.error(f"ë ˆì§ ë¶„ì„ìš© ìºì‹œ ì‚¬ì „ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())

def preload_scan_cache_kr(limit: int = 200):
    """í•œêµ­ ì£¼ì‹ ìŠ¤ìº”ìš© ìºì‹œ ì‚¬ì „ ìƒì„± (ê³¼ê±° ë°ì´í„°ë§Œ, ì„ íƒì )"""
    if not is_trading_day():
        logger.info("ì˜¤ëŠ˜ì€ ê±°ë˜ì¼ì´ ì•„ë‹™ë‹ˆë‹¤. ìŠ¤ìº”ìš© ìºì‹œ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    try:
        logger.info(f"ğŸ“ˆ ìŠ¤ìº”ìš© ìºì‹œ ì‚¬ì „ ìƒì„± ì‹œì‘ (í•œêµ­, ìƒìœ„ {limit}ê°œ ì¢…ëª©)")
        
        from kiwoom_api import api
        
        # ìœ ë‹ˆë²„ìŠ¤ ë¡œë“œ
        kospi_codes = api.get_top_codes("KOSPI", limit // 2)
        kosdaq_codes = api.get_top_codes("KOSDAQ", limit // 2)
        universe = kospi_codes + kosdaq_codes
        
        logger.info(f"ìœ ë‹ˆë²„ìŠ¤ ë¡œë“œ ì™„ë£Œ: {len(universe)}ê°œ ì¢…ëª©")
        
        # ê³¼ê±° 30ì¼ ë°ì´í„°ë§Œ ì‚¬ì „ ìƒì„±
        today = datetime.now()
        success_count = 0
        for code in universe:
            try:
                for days_ago in range(1, 31):  # ìµœê·¼ 30ì¼
                    past_date = (today - timedelta(days=days_ago)).strftime('%Y%m%d')
                    # base_dtë¥¼ ì§€ì •í•˜ì—¬ ê³¼ê±° ë‚ ì§œ ë°ì´í„°ë§Œ ìƒì„±
                    api.get_ohlcv(code, 220, past_date)
                success_count += 1
            except Exception as e:
                logger.warning(f"{code} ìºì‹œ ìƒì„± ì‹¤íŒ¨: {e}")
        
        logger.info(f"âœ… ìŠ¤ìº”ìš© ìºì‹œ ì‚¬ì „ ìƒì„± ì™„ë£Œ: {success_count}/{len(universe)}ê°œ ì¢…ëª©")
        
    except Exception as e:
        logger.error(f"ìŠ¤ìº”ìš© ìºì‹œ ì‚¬ì „ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())

def preload_scan_cache_us(limit: int = 200):
    """ë¯¸êµ­ ì£¼ì‹ ìŠ¤ìº”ìš© ìºì‹œ ì‚¬ì „ ìƒì„± (ê³¼ê±° ë°ì´í„°ë§Œ, ì„ íƒì )"""
    if not is_us_trading_day():
        logger.info("ì˜¤ëŠ˜ì€ ë¯¸êµ­ ê±°ë˜ì¼ì´ ì•„ë‹™ë‹ˆë‹¤. ìŠ¤ìº”ìš© ìºì‹œ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    try:
        logger.info(f"ğŸ“ˆ ìŠ¤ìº”ìš© ìºì‹œ ì‚¬ì „ ìƒì„± ì‹œì‘ (ë¯¸êµ­, ìƒìœ„ {limit}ê°œ ì¢…ëª©)")
        
        from services.us_stocks_universe import USStocksUniverse
        from services.us_stocks_data import us_stocks_data
        
        us_universe = USStocksUniverse()
        
        # ìœ ë‹ˆë²„ìŠ¤ ë¡œë“œ
        symbols = us_universe.get_combined_universe(limit=limit)
        symbol_list = [item['symbol'] for item in symbols]
        
        logger.info(f"ìœ ë‹ˆë²„ìŠ¤ ë¡œë“œ ì™„ë£Œ: {len(symbol_list)}ê°œ ì¢…ëª©")
        
        # ê³¼ê±° 30ì¼ ë°ì´í„°ë§Œ ì‚¬ì „ ìƒì„±
        today = datetime.now()
        success_count = 0
        for symbol in symbol_list:
            try:
                for days_ago in range(1, 31):  # ìµœê·¼ 30ì¼
                    past_date = (today - timedelta(days=days_ago)).strftime('%Y%m%d')
                    # base_dtë¥¼ ì§€ì •í•˜ì—¬ ê³¼ê±° ë‚ ì§œ ë°ì´í„°ë§Œ ìƒì„±
                    us_stocks_data.get_ohlcv(symbol, 220, past_date)
                success_count += 1
            except Exception as e:
                logger.warning(f"{symbol} ìºì‹œ ìƒì„± ì‹¤íŒ¨: {e}")
        
        logger.info(f"âœ… ìŠ¤ìº”ìš© ìºì‹œ ì‚¬ì „ ìƒì„± ì™„ë£Œ: {success_count}/{len(symbol_list)}ê°œ ì¢…ëª©")
        
    except Exception as e:
        logger.error(f"ìŠ¤ìº”ìš© ìºì‹œ ì‚¬ì „ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())

def run_validation():
    """ë°ì´í„° í™•ì • ì‹œì  ê²€ì¦ (15:31~15:40)"""
    if not is_trading_day():
        return
    
    try:
        logger.info("ğŸ” ì¥ì„¸ ë°ì´í„° ê²€ì¦ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        import subprocess
        result = subprocess.run(
            ["python", "validate_market_data_timing.py"],
            cwd="/home/ubuntu/showmethestock/backend",
            capture_output=True,
            text=True
        )
        if result.returncode == 0:
            logger.info("âœ… ê²€ì¦ ì™„ë£Œ")
        else:
            logger.error(f"âŒ ê²€ì¦ ì‹¤íŒ¨: {result.stderr}")
    except Exception as e:
        logger.error(f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def setup_scheduler():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • - KST ê¸°ì¤€"""
    # === ë ˆì§ ë¶„ì„ìš© ìºì‹œ ì‚¬ì „ ìƒì„± (í•„ìˆ˜) ===
    
    # í•œêµ­ ì£¼ì‹: ì¥ ë§ˆê° ì§í›„ (15:35)
    schedule.every().day.at("15:35").do(preload_regime_cache_kr)
    # - KOSPI: FinanceDataReader (ìë™)
    # - KOSDAQ: CSV ìºì‹œ í™•ì¸/ìƒì„±
    # - SPY/QQQ/VIX: us_futures_data_v8.fetch_data()
    
    # ë¯¸êµ­ ì£¼ì‹: ë¯¸êµ­ ì¥ ë§ˆê° í›„ (06:50)
    schedule.every().day.at("06:50").do(preload_regime_cache_us)
    # - SPY/QQQ/VIX/ES=F/NQ=F/DX-Y.NYB: us_futures_data_v8.fetch_data()
    
    # === ìŠ¤ìº”ìš© ìºì‹œ ì‚¬ì „ ìƒì„± (ì„ íƒì ) ===
    
    # í•œêµ­ ì£¼ì‹: ìŠ¤ìº” 30ë¶„ ì „ (15:12)
    # schedule.every().day.at("15:12").do(preload_scan_cache_kr)
    # - ìƒìœ„ 200ê°œ ì¢…ëª©ì˜ ê³¼ê±° 30ì¼ ë°ì´í„°ë§Œ ìƒì„±
    # - ë‹¹ì¼ ë°ì´í„°ëŠ” ìƒì„±í•˜ì§€ ì•ŠìŒ
    # ì£¼ì„ ì²˜ë¦¬: ì„ íƒì  ê¸°ëŠ¥ì´ë¯€ë¡œ í•„ìš” ì‹œ í™œì„±í™”
    
    # ë¯¸êµ­ ì£¼ì‹: ìŠ¤ìº” 30ë¶„ ì „ (06:30)
    # schedule.every().day.at("06:30").do(preload_scan_cache_us)
    # - ìƒìœ„ 200ê°œ ì¢…ëª©ì˜ ê³¼ê±° 30ì¼ ë°ì´í„°ë§Œ ìƒì„±
    # - ë‹¹ì¼ ë°ì´í„°ëŠ” ìƒì„±í•˜ì§€ ì•ŠìŒ
    # ì£¼ì„ ì²˜ë¦¬: ì„ íƒì  ê¸°ëŠ¥ì´ë¯€ë¡œ í•„ìš” ì‹œ í™œì„±í™”
    
    # === í•œêµ­ ì£¼ì‹ ìŠ¤ìº” ===
    # ë°ì´í„° í™•ì • ì‹œì  ê²€ì¦ (15:31~15:40, ë§¤ë¶„)
    schedule.every().day.at("15:31").do(run_validation)
    schedule.every().day.at("15:32").do(run_validation)
    schedule.every().day.at("15:33").do(run_validation)
    schedule.every().day.at("15:34").do(run_validation)
    schedule.every().day.at("15:35").do(run_validation)
    schedule.every().day.at("15:36").do(run_validation)
    schedule.every().day.at("15:37").do(run_validation)
    schedule.every().day.at("15:38").do(run_validation)
    schedule.every().day.at("15:39").do(run_validation)
    schedule.every().day.at("15:40").do(run_validation)
    
    # ë§¤ì¼ ì˜¤í›„ 3ì‹œ 40ë¶„ì— ì¥ì„¸ ë¶„ì„ ì‹¤í–‰ (ë°ì´í„° í™•ì • í›„) - KST ê¸°ì¤€
    schedule.every().day.at("15:40").do(run_market_analysis)
    # - ë ˆì§ ë¶„ì„ìš© ìºì‹œ ì‚¬ìš© âœ…
    
    # ë§¤ì¼ ì˜¤í›„ 3ì‹œ 42ë¶„ì— í•œêµ­ ì£¼ì‹ ìŠ¤ìº” ì‹¤í–‰ (ì¥ì„¸ ë¶„ì„ í›„) - KST ê¸°ì¤€
    schedule.every().day.at("15:42").do(run_scan)
    # - ê³¼ê±° ë°ì´í„°: ì‚¬ì „ ìƒì„±ëœ ìºì‹œ ì‚¬ìš© âœ… (ì„ íƒì )
    # - ë‹¹ì¼ ë°ì´í„°: ìŠ¤ìº” ì‹œì ì— ìƒì„± (ìµœì‹  ë°ì´í„° ë³´ì¥)
    
    # === ë¯¸êµ­ ì£¼ì‹ ìŠ¤ìº” ===
    # ë§¤ì¼ ì˜¤ì „ 7ì‹œì— ë¯¸êµ­ ì£¼ì‹ ìŠ¤ìº” ì‹¤í–‰ (ë¯¸êµ­ ì‹œì¥ ë§ˆê° í›„ ë°ì´í„° í™•ì • ì‹œì ) - KST ê¸°ì¤€
    # ì„œë¨¸íƒ€ì„: ë¯¸êµ­ ì •ê·œì¥ ë§ˆê° 5:00 KST â†’ ìŠ¤ìº” 7:00 KST
    # ë¹„ì„œë¨¸íƒ€ì„: ë¯¸êµ­ ì •ê·œì¥ ë§ˆê° 6:00 KST â†’ ìŠ¤ìº” 7:00 KST
    schedule.every().day.at("07:00").do(run_us_scan)
    # - ê³¼ê±° ë°ì´í„°: ì‚¬ì „ ìƒì„±ëœ ìºì‹œ ì‚¬ìš© âœ… (ì„ íƒì )
    # - ë‹¹ì¼ ë°ì´í„°: ìŠ¤ìº” ì‹œì ì— ìƒì„± (ìµœì‹  ë°ì´í„° ë³´ì¥)
    
    logger.info("ìë™ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    logger.info("=== ë ˆì§ ë¶„ì„ìš© ìºì‹œ ì‚¬ì „ ìƒì„± (í•„ìˆ˜) ===")
    logger.info("- ë§¤ì¼ ì˜¤í›„ 3:35 KST: í•œêµ­ ì£¼ì‹ ë ˆì§ ë¶„ì„ìš© ìºì‹œ ìƒì„±")
    logger.info("- ë§¤ì¼ ì˜¤ì „ 6:50 KST: ë¯¸êµ­ ì£¼ì‹ ë ˆì§ ë¶„ì„ìš© ìºì‹œ ìƒì„±")
    logger.info("=== ìŠ¤ìº”ìš© ìºì‹œ ì‚¬ì „ ìƒì„± (ì„ íƒì ) ===")
    logger.info("- ì£¼ì„ ì²˜ë¦¬ë¨: í•„ìš” ì‹œ 15:12 (í•œêµ­), 06:30 (ë¯¸êµ­) í™œì„±í™”")
    logger.info("=== í•œêµ­ ì£¼ì‹ ===")
    logger.info("- ë§¤ì¼ ì˜¤í›„ 3:31~3:40 KST: ë°ì´í„° ê²€ì¦ (ë§¤ë¶„)")
    logger.info("- ë§¤ì¼ ì˜¤í›„ 3:40 KST: ì¥ì„¸ ë¶„ì„ ì‹¤í–‰ (ë ˆì§ ë¶„ì„ìš© ìºì‹œ ì‚¬ìš©)")
    logger.info("- ë§¤ì¼ ì˜¤í›„ 3:42 KST: í•œêµ­ ì£¼ì‹ ìŠ¤ìº” ì‹¤í–‰")
    logger.info("=== ë¯¸êµ­ ì£¼ì‹ ===")
    logger.info("- ë§¤ì¼ ì˜¤ì „ 7:00 KST: ë¯¸êµ­ ì£¼ì‹ ìŠ¤ìº” ì‹¤í–‰")
    logger.info("- ì£¼ë§ê³¼ ê³µíœ´ì¼ì€ ìë™ìœ¼ë¡œ ì œì™¸ë©ë‹ˆë‹¤.")

def run_scheduler():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰"""
    setup_scheduler()
    
    while True:
        schedule.run_pending()
        time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬

if __name__ == "__main__":
    run_scheduler()
