#!/usr/bin/env python3
"""
ìºì‹œ ê¸°ë°˜ ëŒ€ëŸ‰ ë ˆì§ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
"""
import sys
import os
from datetime import datetime, timedelta
import json

# backend ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), 'backend'))

def bulk_regime_analysis_cached(start_date, end_date):
    """ìºì‹œ ê¸°ë°˜ ëŒ€ëŸ‰ ë ˆì§ ë¶„ì„"""
    try:
        from services.regime_analyzer_cached import regime_analyzer_cached
        
        print(f"ğŸ“Š ìºì‹œ ê¸°ë°˜ ëŒ€ëŸ‰ ë ˆì§ ë¶„ì„: {start_date} ~ {end_date}")
        
        # ë‚ ì§œ ë²”ìœ„ ìƒì„±
        start_dt = datetime.strptime(start_date, '%Y%m%d')
        end_dt = datetime.strptime(end_date, '%Y%m%d')
        
        results = {}
        regime_counts = {}
        total_days = 0
        
        current_dt = start_dt
        while current_dt <= end_dt:
            date_str = current_dt.strftime('%Y%m%d')
            
            try:
                # ìºì‹œ ê¸°ë°˜ ë¶„ì„
                result = regime_analyzer_cached.analyze_regime_v4_cached(date_str)
                
                results[date_str] = {
                    'date': date_str,
                    'final_regime': result['final_regime'],
                    'final_score': result['final_score'],
                    'kr_regime': result['kr_regime'],
                    'kr_score': result['kr_score'],
                    'us_prev_regime': result['us_prev_regime'],
                    'us_prev_score': result['us_prev_score'],
                    'us_futures_regime': result['us_futures_regime'],
                    'us_futures_score': result['us_futures_score']
                }
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                regime = result['final_regime']
                regime_counts[regime] = regime_counts.get(regime, 0) + 1
                total_days += 1
                
                print(f"  {date_str}: {result['final_regime']} ({result['final_score']:.2f})")
                
            except Exception as e:
                print(f"  {date_str}: ì˜¤ë¥˜ - {e}")
                results[date_str] = {'date': date_str, 'error': str(e)}
            
            current_dt += timedelta(days=1)
        
        # ê²°ê³¼ ìš”ì•½
        print(f"\nğŸ“ˆ ë¶„ì„ ê²°ê³¼ ìš”ì•½:")
        print(f"  ì´ ë¶„ì„ì¼: {total_days}ì¼")
        print(f"  ë ˆì§ ë¶„í¬:")
        for regime, count in regime_counts.items():
            pct = (count / total_days * 100) if total_days > 0 else 0
            print(f"    {regime}: {count}ì¼ ({pct:.1f}%)")
        
        # ê²°ê³¼ ì €ì¥
        output_file = f"bulk_regime_cached_{start_date}_{end_date}.json"
        summary = {
            'analysis_date': datetime.now().isoformat(),
            'period': f"{start_date} ~ {end_date}",
            'total_days': total_days,
            'regime_distribution': regime_counts,
            'daily_results': results,
            'cache_based': True
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
        
        # ìºì‹œ í†µê³„
        cache_stats = regime_analyzer_cached.get_cache_stats()
        print(f"\nğŸ“Š ìºì‹œ í†µê³„:")
        print(f"  ìºì‹œ íŒŒì¼: {cache_stats.get('total_files', 0)}ê°œ")
        print(f"  ìºì‹œ í¬ê¸°: {cache_stats.get('total_size', 0):,} bytes")
        
        return summary
        
    except Exception as e:
        print(f"âŒ ëŒ€ëŸ‰ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return None

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='ìºì‹œ ê¸°ë°˜ ëŒ€ëŸ‰ ë ˆì§ ë¶„ì„')
    parser.add_argument('--start', required=True, help='ì‹œì‘ ë‚ ì§œ (YYYYMMDD)')
    parser.add_argument('--end', required=True, help='ì¢…ë£Œ ë‚ ì§œ (YYYYMMDD)')
    
    args = parser.parse_args()
    
    print("ğŸš€ ìºì‹œ ê¸°ë°˜ ëŒ€ëŸ‰ ë ˆì§ ë¶„ì„ ì‹œì‘\n")
    bulk_regime_analysis_cached(args.start, args.end)
    print("\nğŸ¯ ì™„ë£Œ!")