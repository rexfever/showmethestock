# 레짐 분석 및 스캔 프로세스 종합 보고서

## 개요

개선된 캐시 전략을 활용한 레짐 분석과 주식 스캔의 전체 프로세스를 정리합니다.

---

## 1. 전체 프로세스 타임라인

### 한국 주식 (KST 기준)

```
15:35 - 레짐 분석용 캐시 증분 업데이트
    ├─▶ KOSPI: 증분 업데이트 (캐시 없으면 초기 생성 365일분)
    ├─▶ KOSDAQ: 증분 업데이트 (캐시 없으면 초기 생성 365일분)
    └─▶ SPY/QQQ/VIX: 증분 업데이트

15:40 - 레짐 분석 실행
    ├─▶ 사전 생성된 캐시 사용 ✅
    ├─▶ Trend Score 계산
    ├─▶ Risk Score 계산
    └─▶ Global Regime 결정 (bull/neutral/bear/crash)

15:42 - 한국 주식 스캔 실행
    ├─▶ 유니버스 구성 (KOSPI 200 + KOSDAQ 200 = 400개)
    ├─▶ 각 종목마다 get_ohlcv(code, 220, None) 호출
    │   ├─▶ 캐시 없음 → 전체 API 호출 (220일분) → 캐시 저장
    │   └─▶ 캐시 있음 → 증분 업데이트 (당일만 추가) ✅
    ├─▶ 지표 계산
    ├─▶ 필터링
    └─▶ 결과 저장 (DB)
```

### 미국 주식 (KST 기준)

```
06:50 - 레짐 분석용 캐시 증분 업데이트
    └─▶ SPY/QQQ/VIX/ES=F/NQ=F/DX-Y.NYB: 증분 업데이트

07:00 - 레짐 분석 실행
    ├─▶ Global Regime v4 사용 (한국+미국 통합 분석)
    ├─▶ 사전 생성된 캐시 사용 ✅
    ├─▶ Trend Score 계산
    ├─▶ Risk Score 계산
    └─▶ Global Regime 결정 (bull/neutral/bear/crash)

07:00 - 미국 주식 스캔 실행
    ├─▶ 유니버스 구성 (S&P 500 + NASDAQ 100)
    ├─▶ 각 종목마다 get_ohlcv(symbol, 220, None) 호출
    │   ├─▶ 캐시 없음 → 전체 API 호출 (220일분) → 캐시 저장
    │   └─▶ 캐시 있음 → 증분 업데이트 (당일만 추가) ✅
    ├─▶ 지표 계산
    ├─▶ 필터링 (레짐 기반 조건 조정) ✅
    ├─▶ 레짐 기반 cutoff 적용 ✅
    └─▶ 결과 저장 (DB)
```

---

## 2. 레짐 분석 프로세스

### 2.1 캐시 증분 업데이트 (15:35)

#### 목적
- 레짐 분석 실패 방지
- 장 마감 후 확정 데이터 사용
- 종목 수 적음 (5개) → 빠른 생성

#### 프로세스

**KOSPI 지수 데이터**:
```python
# backend/utils/regime_cache_manager.py - update_kospi_cache_incremental()

1. 기존 캐시 로드
   └─▶ load_kospi_cache()
       └─▶ data_cache/kospi200_ohlcv.pkl

2. 캐시 상태 확인
   ├─▶ 캐시 없음 → 초기 생성 (365일분)
   │   └─▶ get_kospi_data(date=today, days=365)
   │       ├─▶ pykrx 우선 (한국거래소 공식 데이터)
   │       ├─▶ FinanceDataReader fallback
   │       └─▶ 캐시 저장
   │
   └─▶ 캐시 있음 → 증분 업데이트
       ├─▶ 캐시의 최신 날짜 확인
       ├─▶ 오늘보다 오래된 경우:
       │   ├─▶ 당일 데이터만 추가 (30일분 가져와서 필터링)
       │   └─▶ 병합 및 캐시 업데이트
       └─▶ 캐시가 최신이면 그대로 사용
```

**KOSDAQ 지수 데이터**:
```python
# backend/utils/regime_cache_manager.py - update_kosdaq_cache_incremental()

1. 기존 캐시 로드
   └─▶ load_kosdaq_cache()
       └─▶ data_cache/ohlcv/229200.csv

2. 캐시 상태 확인
   ├─▶ 캐시 없음 → 초기 생성 (365일분)
   │   └─▶ api.get_ohlcv("229200", 365, today)
   │       └─▶ CSV 캐시 저장
   │
   └─▶ 캐시 있음 → 증분 업데이트
       ├─▶ 캐시의 최신 날짜 확인
       ├─▶ 오늘보다 오래된 경우:
       │   ├─▶ 당일 데이터만 추가 (5일분 가져와서 필터링)
       │   └─▶ 병합 및 캐시 업데이트
       └─▶ 캐시가 최신이면 그대로 사용
```

**미국 선물 데이터 (SPY/QQQ/VIX)**:
```python
# backend/services/us_futures_data_v8.py - fetch_data()

1. CSV 캐시 로드
   └─▶ cache/us_futures/{symbol}.csv

2. 증분 업데이트
   ├─▶ 캐시의 최신 날짜 확인
   ├─▶ 1일 이상 오래된 경우:
   │   ├─▶ Chart API로 최신 데이터 가져오기
   │   └─▶ 병합 및 캐시 업데이트
   └─▶ 캐시가 최신이면 그대로 사용
```

#### 성능
- **소요 시간**: 약 10초 (이전: 1분)
- **API 호출**: 최소화 (당일 데이터만)
- **효율성**: 6배 향상

---

### 2.2 레짐 분석 실행 (15:40)

#### 프로세스

```python
# backend/scheduler.py - run_market_analysis()
# backend/market_analyzer.py - analyze_market_condition()

1. 레짐 버전 확인
   └─▶ config.regime_version (v1/v3/v4)

2. 데이터 로드 (사전 생성된 캐시 사용)
   ├─▶ KOSPI: get_kospi_data() → 캐시 사용 ✅
   ├─▶ KOSDAQ: load_kosdaq_cache() → CSV 캐시 사용 ✅
   └─▶ SPY/QQQ/VIX: us_futures_data_v8.fetch_data() → CSV 캐시 사용 ✅

3. 레짐 분석 수행
   ├─▶ [v4] Global Regime Analyzer
   │   ├─▶ Trend Score 계산
   │   │   ├─▶ 한국: KOSPI/KOSDAQ 트렌드 분석
   │   │   └─▶ 미국: SPY/QQQ/VIX 트렌드 분석
   │   ├─▶ Risk Score 계산
   │   │   ├─▶ 한국: 변동성, RSI 등
   │   │   └─▶ 미국: VIX, 변동성 등
   │   └─▶ Global Regime 결정
   │       └─▶ bull/neutral/bear/crash
   │
   ├─▶ [v3] Regime Analyzer v3
   │   └─▶ 점수 기반 레짐 결정
   │
   └─▶ [v1] 기본 장세 분석
       └─▶ KOSPI 수익률, RSI 등

4. 결과 저장 (DB)
   └─▶ market_conditions 테이블
       ├─▶ date
       ├─▶ market_sentiment (또는 final_regime)
       ├─▶ sentiment_score (또는 final_score)
       └─▶ 기타 지표들
```

#### 특징
- ✅ **API 호출 없음** (사전 생성된 캐시만 사용)
- ✅ **빠른 실행** (약 1-2초)
- ✅ **안정성** (캐시 기반)

---

## 3. 스캔 프로세스

### 3.1 한국 주식 스캔 (15:42)

#### 프로세스

```python
# backend/scheduler.py - run_scan()
# backend/main.py - scan()

1. 유니버스 구성
   ├─▶ KOSPI 상위 200개
   └─▶ KOSDAQ 상위 200개
   └─▶ 총 400개 종목

2. 각 종목 스캔
   └─▶ for code in universe:
       ├─▶ OHLCV 데이터 가져오기
       │   └─▶ api.get_ohlcv(code, 220, None)
       │       │
       │       ├─▶ [케이스 1] 메모리 캐시 확인
       │       │   └─▶ 캐시 있으면 반환 ✅
       │       │
       │       ├─▶ [케이스 2] 디스크 캐시 확인
       │       │   ├─▶ 최신 캐시 찾기
       │       │   ├─▶ 캐시의 최신 날짜 확인
       │       │   └─▶ 오늘보다 오래된 경우:
       │       │       ├─▶ 과거 데이터: 캐시에서 사용 ✅
       │       │       ├─▶ 당일 데이터: API로 추가 ✅
       │       │       └─▶ 병합 및 캐시 업데이트 ✅
       │       │
       │       └─▶ [케이스 3] 캐시 없음
       │           └─▶ 전체 API 호출 (220일분)
       │               └─▶ 캐시 저장 (메모리 + 디스크)
       │
       ├─▶ 지표 계산
       │   ├─▶ 기술적 지표 (RSI, MACD, 볼린저 밴드 등)
       │   ├─▶ 가격 지표 (등락률, 거래량 등)
       │   └─▶ 점수 계산
       │
       ├─▶ 필터링
       │   ├─▶ 레짐별 필터 적용
       │   ├─▶ 점수 기준 필터
       │   └─▶ 기타 필터 (외국 ETF 제외 등)
       │
       └─▶ 결과 저장
           └─▶ scan_ranks 테이블
               ├─▶ date
               ├─▶ ticker
               ├─▶ score
               ├─▶ strategy
               └─▶ 기타 지표들
```

#### 캐시 활용

**증분 업데이트 로직**:
```python
# backend/kiwoom_api.py - get_ohlcv()

1. 메모리 캐시 확인
   └─▶ 캐시 있으면 반환 ✅

2. 디스크 캐시 확인 (base_dt=None일 때)
   ├─▶ 최신 캐시 찾기 (_find_latest_disk_cache())
   ├─▶ 캐시의 최신 날짜 확인
   └─▶ 오늘보다 오래된 경우:
       ├─▶ 과거 데이터: 캐시에서 사용 ✅
       ├─▶ 당일 데이터: API로 추가 ✅
       └─▶ 병합 및 캐시 업데이트 ✅

3. 캐시 없음
   └─▶ 전체 API 호출 (220일분)
       └─▶ 캐시 저장
```

#### 성능
- **소요 시간**: 약 3-5분 (이전: 5-10분)
- **API 호출**: 최소화 (과거 데이터는 캐시에서)
- **효율성**: 2배 향상

---

### 3.2 미국 주식 스캔 (07:00)

#### 프로세스

```python
# backend/scheduler.py - run_us_scan()
# backend/main.py - scan_us_stocks()

1. 유니버스 구성
   ├─▶ S&P 500
   └─▶ NASDAQ 100
   └─▶ 총 약 600개 종목

2. 각 종목 스캔
   └─▶ for symbol in universe:
       ├─▶ OHLCV 데이터 가져오기
       │   └─▶ us_stocks_data.get_ohlcv(symbol, 220, None)
       │       │
       │       ├─▶ [케이스 1] CSV 캐시 확인
       │       │   ├─▶ 캐시 있음:
       │       │   │   ├─▶ 과거 데이터: 캐시에서 사용 ✅
       │       │   │   ├─▶ 당일 데이터: API로 추가 ✅
       │       │   │   └─▶ 병합 및 캐시 업데이트 ✅
       │       │   │
       │       │   └─▶ 캐시 없음:
       │       │       └─▶ 전체 API 호출 (220일분)
       │       │           └─▶ 캐시 저장
       │       │
       │       └─▶ [케이스 2] 캐시 없음
       │           └─▶ 전체 API 호출 (220일분)
       │               └─▶ 캐시 저장
       │
       ├─▶ 지표 계산
       │   ├─▶ 기술적 지표
       │   ├─▶ 가격 지표
       │   └─▶ 점수 계산
       │
       ├─▶ 필터링
       │   ├─▶ 하드 필터 (ETF, 유동성, 가격 등)
       │   ├─▶ 소프트 필터 (지표 기반)
       │   └─▶ 점수 기준 필터
       │   └─▶ 주의: 레짐 분석 없이 직접 필터링 (추후 레짐 분석 추가 예정)
       │
       └─▶ 결과 저장
           └─▶ us_scan_ranks 테이블
```

#### 특징

**레짐 분석 적용**:
- Global Regime v4 사용 (한국+미국 통합 분석)
- 레짐 기반 cutoff 적용 (bull/neutral/bear/crash별 점수 기준)
- 레짐 기반 필터링 조건 조정 (RSI 임계값, 최소 신호 개수, 거래량 배수)
- 강세장/약세장에 따른 조건 완화/강화

#### 캐시 활용

**증분 업데이트 로직**:
```python
# backend/services/us_stocks_data.py - get_ohlcv()

1. CSV 캐시 확인
   └─▶ cache/us_stocks_ohlcv/{symbol}.csv

2. 캐시 상태 확인
   ├─▶ 캐시 있음:
   │   ├─▶ 캐시의 최신 날짜 확인
   │   ├─▶ 오늘보다 오래된 경우:
   │   │   ├─▶ 과거 데이터: 캐시에서 사용 ✅
   │   │   ├─▶ 당일 데이터: Chart API로 추가 ✅
   │   │   └─▶ 병합 및 캐시 업데이트 ✅
   │   │
   │   └─▶ 캐시가 최신이면 그대로 사용 ✅
   │
   └─▶ 캐시 없음:
       └─▶ 전체 API 호출 (220일분)
           └─▶ 캐시 저장
```

---

## 4. 캐시 전략 통일

### 4.1 모든 캐시가 동일한 방식

**증분 업데이트 방식**:
1. 캐시 확인
2. 캐시 없으면 초기 생성 (전체 데이터)
3. 캐시 있으면 증분 업데이트 (당일만 추가)
4. 병합 및 저장

### 4.2 캐시 종류별 상세

#### 레짐 분석용 캐시

| 종목 | 데이터 소스 | 캐시 위치 | 생성 시점 | 사용 시점 | 업데이트 방식 |
|------|------------|----------|----------|----------|--------------|
| **KOSPI** | pykrx > FinanceDataReader | `data_cache/kospi200_ohlcv.pkl` | 15:35 | 15:40 | 증분 업데이트 ✅ |
| **KOSDAQ** | 키움 API (229200) | `data_cache/ohlcv/229200.csv` | 15:35 | 15:40 | 증분 업데이트 ✅ |
| **SPY** | Yahoo Finance Chart API | `cache/us_futures/SPY.csv` | 15:35 | 15:40 | 증분 업데이트 ✅ |
| **QQQ** | Yahoo Finance Chart API | `cache/us_futures/QQQ.csv` | 15:35 | 15:40 | 증분 업데이트 ✅ |
| **VIX** | Yahoo Finance Chart API | `cache/us_futures/^VIX.csv` | 15:35 | 15:40 | 증분 업데이트 ✅ |

**특징**:
- 종목 수 적음 (5개)
- 생성 시간 짧음 (약 10초)
- 증분 업데이트 방식

#### 스캔용 캐시 (한국 주식)

| 항목 | 내용 |
|------|------|
| **캐시 타입** | 메모리 캐시 + 디스크 캐시 |
| **메모리 캐시** | `{(code, count, base_dt, hour_key): (df, timestamp)}` |
| **디스크 캐시** | `cache/ohlcv/{code}_{count}_{base_dt}.pkl` |
| **TTL** | 동적 계산 (장중 1분, 장 마감 후 24시간) |
| **업데이트 방식** | 증분 업데이트 ✅ |
| **자동 관리** | `get_ohlcv()` 함수가 자동 처리 |

**특징**:
- 종목 수 많음 (400개)
- 생성 시간 김 (약 3-5분)
- 증분 업데이트 방식

#### 스캔용 캐시 (미국 주식)

| 항목 | 내용 |
|------|------|
| **캐시 타입** | CSV 캐시 |
| **캐시 위치** | `cache/us_stocks_ohlcv/{symbol}.csv` |
| **업데이트 방식** | 증분 업데이트 ✅ |
| **자동 관리** | `get_ohlcv()` 함수가 자동 처리 |

**특징**:
- 종목 수 많음 (약 600개)
- 생성 시간 김 (약 5-10분)
- 증분 업데이트 방식

---

## 5. 데이터 흐름도

### 레짐 분석 데이터 흐름

```
[15:35] 캐시 증분 업데이트
    │
    ├─▶ KOSPI
    │   ├─▶ 캐시 확인
    │   ├─▶ 없음 → 초기 생성 (365일)
    │   └─▶ 있음 → 증분 업데이트 (당일만)
    │
    ├─▶ KOSDAQ
    │   ├─▶ 캐시 확인
    │   ├─▶ 없음 → 초기 생성 (365일)
    │   └─▶ 있음 → 증분 업데이트 (당일만)
    │
    └─▶ SPY/QQQ/VIX
        └─▶ 증분 업데이트

[15:40] 레짐 분석
    │
    ├─▶ 캐시에서 데이터 로드
    │   ├─▶ KOSPI: get_kospi_data() → 캐시 사용
    │   ├─▶ KOSDAQ: load_kosdaq_cache() → CSV 캐시 사용
    │   └─▶ SPY/QQQ/VIX: us_futures_data_v8.fetch_data() → CSV 캐시 사용
    │
    ├─▶ Trend Score 계산
    ├─▶ Risk Score 계산
    └─▶ Global Regime 결정
        └─▶ DB 저장
```

### 스캔 데이터 흐름

```
[15:42] 한국 주식 스캔
    │
    ├─▶ 유니버스 구성 (400개)
    │
    └─▶ 각 종목마다:
        │
        ├─▶ get_ohlcv(code, 220, None)
        │   │
        │   ├─▶ 메모리 캐시 확인
        │   │   └─▶ 있으면 반환 ✅
        │   │
        │   ├─▶ 디스크 캐시 확인
        │   │   ├─▶ 최신 캐시 찾기
        │   │   ├─▶ 캐시의 최신 날짜 확인
        │   │   └─▶ 오래된 경우:
        │   │       ├─▶ 과거 데이터: 캐시에서 사용 ✅
        │   │       ├─▶ 당일 데이터: API로 추가 ✅
        │   │       └─▶ 병합 및 캐시 업데이트 ✅
        │   │
        │   └─▶ 캐시 없음
        │       └─▶ 전체 API 호출 (220일)
        │           └─▶ 캐시 저장
        │
        ├─▶ 지표 계산
        ├─▶ 필터링
        └─▶ 결과 저장 (DB)
```

---

## 6. 핵심 개선 사항

### 6.1 캐시 전략 통일

**이전**:
- 레짐 분석용 캐시: 매일 전체 재생성
- 스캔용 캐시: 증분 업데이트

**개선 후**:
- 모든 캐시: 증분 업데이트 방식으로 통일 ✅

**효과**:
- 일관성 확보
- 효율성 향상 (레짐 캐시: 1분 → 10초)
- 코드 유지보수성 향상

### 6.2 인덱스 타입 통일

**문제**: DataFrame 인덱스 타입 불일치

**해결**: `ensure_datetime_index()` 함수 추가
- DatetimeIndex가 이미 있으면 그대로 반환
- date 컬럼이 있으면 인덱스로 변환
- 자동 타입 통일

### 6.3 날짜 비교 로직 개선

**문제**: 시간대 문제 가능

**해결**: `compare_dates_only()` 함수 추가
- `normalize()`를 사용하여 날짜만 비교
- 시간 정보 무시

### 6.4 캐시 병합 로직 통일

**문제**: 중복 코드 및 일관성 부족

**해결**: `merge_cache_data()` 함수 추가
- 인덱스 타입 통일
- 중복 제거
- 정렬
- 크기 제한

---

## 7. 성능 개선 효과

### 레짐 분석용 캐시

| 항목 | 이전 | 개선 후 | 개선 효과 |
|------|------|--------|----------|
| **KOSPI** | 전체 재생성 (365일) | 증분 업데이트 (당일만) | ⭐⭐⭐⭐⭐ |
| **KOSDAQ** | 전체 재생성 (365일) | 증분 업데이트 (당일만) | ⭐⭐⭐⭐⭐ |
| **SPY/QQQ/VIX** | 전체 재생성 | 증분 업데이트 | ⭐⭐⭐⭐⭐ |
| **소요 시간** | ~1분 | ~10초 | **6배 단축** |

### 스캔용 캐시

| 항목 | 이전 | 개선 후 | 개선 효과 |
|------|------|--------|----------|
| **한국 주식** | 증분 업데이트 | 증분 업데이트 (개선) | ⭐⭐⭐⭐ |
| **미국 주식** | 증분 업데이트 | 증분 업데이트 | ⭐⭐⭐⭐⭐ |
| **소요 시간** | 5-10분 | 3-5분 | **2배 단축** |

---

## 8. 프로세스 요약

### 레짐 분석 프로세스 (한국 주식만)

1. **캐시 증분 업데이트 (15:35)**
   - KOSPI: 증분 업데이트 (캐시 없으면 초기 생성)
   - KOSDAQ: 증분 업데이트 (캐시 없으면 초기 생성)
   - SPY/QQQ/VIX: 증분 업데이트

2. **레짐 분석 실행 (15:40)**
   - 사전 생성된 캐시 사용
   - Trend Score 계산
   - Risk Score 계산
   - Global Regime 결정
   - DB 저장

**미국 주식도 레짐 분석 적용**:
- Global Regime v4 사용 (한국+미국 통합 분석)
- 레짐 기반 cutoff 및 필터링 조건 조정

### 스캔 프로세스

#### 한국 주식 스캔

1. **레짐 분석 실행** (15:40)
   - 시장 상황 분석
   - 레짐 결정

2. **유니버스 구성** (15:42)
   - KOSPI 200 + KOSDAQ 200 = 400개

3. **각 종목 스캔**
   - OHLCV 데이터 가져오기 (증분 업데이트)
   - 지표 계산
   - 필터링 (레짐 기반)
   - 결과 저장 (DB)

#### 미국 주식 스캔

1. **레짐 분석 실행** (07:00)
   - Global Regime v4 사용 (한국+미국 통합 분석)
   - 시장 상황 분석
   - 레짐 결정

2. **유니버스 구성** (07:00)
   - S&P 500 + NASDAQ 100 = 약 600개

3. **각 종목 스캔**
   - OHLCV 데이터 가져오기 (증분 업데이트)
   - 지표 계산
   - 필터링 (레짐 기반 조건 조정)
   - 레짐 기반 cutoff 적용
   - 결과 저장 (DB)

---

## 9. 결론

### 통일된 캐시 전략

모든 캐시가 **증분 업데이트 방식**으로 통일되었습니다:

1. ✅ **레짐 분석용 캐시**: 증분 업데이트
2. ✅ **스캔용 캐시 (한국)**: 증분 업데이트
3. ✅ **스캔용 캐시 (미국)**: 증분 업데이트

### 개선 효과

1. **효율성**: 레짐 캐시 생성 시간 6배 단축
2. **일관성**: 모든 캐시가 동일한 방식
3. **안정성**: 인덱스 타입 통일, 날짜 비교 개선
4. **유지보수성**: 재사용 가능한 함수, 중복 코드 제거

### 핵심 포인트

- **레짐 분석**: 사전 생성된 캐시만 사용 (API 호출 없음)
- **스캔**: 과거 데이터는 캐시에서, 당일 데이터만 API 호출
- **통일성**: 모든 캐시가 동일한 증분 업데이트 방식

**전체 프로세스가 효율적이고 안정적으로 동작합니다.**

